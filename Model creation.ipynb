{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading \n",
    "import pandas as pd \n",
    "\n",
    "# Array math \n",
    "import numpy as np\n",
    "\n",
    "# Dates \n",
    "import datetime\n",
    "\n",
    "# Ploting \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf \n",
    "\n",
    "# Keras API \n",
    "from tensorflow import keras\n",
    "\n",
    "# Deep learning \n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read municipality data in 0.38 seconds\n",
      "Rows read: 13853\n",
      "Read patient data in 0.61 seconds\n",
      "Rows read: 34758\n",
      "Data saved in data/2020-11-16\n"
     ]
    }
   ],
   "source": [
    "# Downloading data \n",
    "!python3 dataDownload.py\n",
    "\n",
    "# Creating tidy data\n",
    "!python3 createTidyData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data \n",
    "d = pd.read_csv('data/tidy_data.csv')\n",
    "\n",
    "# Sorting by date \n",
    "d['day'] = [datetime.datetime.strptime(x, '%Y-%m-%d').date() for x in d['day']]\n",
    "d.sort_values('day', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the last row for prediction \n",
    "xtest = d.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the Y column\n",
    "Y = d['is_covid'].values.tolist()\n",
    "\n",
    "# Lagging all the data \n",
    "d = d.shift(1)\n",
    "d['Y'] = Y\n",
    "\n",
    "# Droping the first row \n",
    "d = d.drop(0)\n",
    "d.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining how many last day data to use in validation \n",
    "n_last = 5\n",
    "\n",
    "# Spliting to training and validation sets \n",
    "validation = d.tail(n_last)\n",
    "train = d[~d.index.isin(validation.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and Y matrices for deep learning \n",
    "X, Y = train.drop(['day', 'Y'], axis=1), train['Y']\n",
    "Xval, Yval = validation.drop(['day', 'Y'], axis=1), validation['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: (244, 102)\n"
     ]
    }
   ],
   "source": [
    "print(f'Input dimension: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_covid</th>\n",
       "      <th>is_cured-0-9Moteris</th>\n",
       "      <th>is_cured-0-9Vyras</th>\n",
       "      <th>is_cured-10-19Moteris</th>\n",
       "      <th>is_cured-10-19Vyras</th>\n",
       "      <th>is_cured-100-109Moteris</th>\n",
       "      <th>is_cured-100-109Vyras</th>\n",
       "      <th>is_cured-120-129Moteris</th>\n",
       "      <th>is_cured-20-29Moteris</th>\n",
       "      <th>is_cured-20-29Vyras</th>\n",
       "      <th>...</th>\n",
       "      <th>is_treated-90-99Vyras</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "      <th>tests_total</th>\n",
       "      <th>is_quarantine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>995.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12002.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1655.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12294.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1941.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14445.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1975.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6570.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_covid  is_cured-0-9Moteris  is_cured-0-9Vyras  is_cured-10-19Moteris  \\\n",
       "239     995.0                  3.0                2.0                    0.0   \n",
       "240    1655.0                  1.0                2.0                    1.0   \n",
       "241    1941.0                  1.0                0.0                    4.0   \n",
       "242    1975.0                  2.0                0.0                    1.0   \n",
       "243    1036.0                  0.0                0.0                    0.0   \n",
       "\n",
       "     is_cured-10-19Vyras  is_cured-100-109Moteris  is_cured-100-109Vyras  \\\n",
       "239                  3.0                      0.0                    0.0   \n",
       "240                  3.0                      0.0                    0.0   \n",
       "241                  1.0                      0.0                    0.0   \n",
       "242                  0.0                      0.0                    0.0   \n",
       "243                  0.0                      0.0                    0.0   \n",
       "\n",
       "     is_cured-120-129Moteris  is_cured-20-29Moteris  is_cured-20-29Vyras  ...  \\\n",
       "239                      0.0                    9.0                  8.0  ...   \n",
       "240                      0.0                    6.0                  8.0  ...   \n",
       "241                      0.0                    2.0                  5.0  ...   \n",
       "242                      0.0                    4.0                  1.0  ...   \n",
       "243                      0.0                    0.0                  0.0  ...   \n",
       "\n",
       "     is_treated-90-99Vyras  weekday_1  weekday_2  weekday_3  weekday_4  \\\n",
       "239                    2.0        0.0        0.0        1.0        0.0   \n",
       "240                    2.0        0.0        0.0        0.0        1.0   \n",
       "241                    2.0        0.0        0.0        0.0        0.0   \n",
       "242                    3.0        0.0        0.0        0.0        0.0   \n",
       "243                    2.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "     weekday_5  weekday_6  weekday_7  tests_total  is_quarantine  \n",
       "239        0.0        0.0        0.0      12002.0            1.0  \n",
       "240        0.0        0.0        0.0      12294.0            1.0  \n",
       "241        1.0        0.0        0.0      14445.0            1.0  \n",
       "242        0.0        1.0        0.0      10574.0            1.0  \n",
       "243        0.0        0.0        1.0       6570.0            1.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239    1655\n",
       "240    1941\n",
       "241    1975\n",
       "242    1036\n",
       "243    1109\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape\n",
    "inputRegression = Input(shape=(X.shape[1], ))\n",
    "\n",
    "# Adding one output linear neuron\n",
    "neuron = Dense(1, activation='linear')(inputRegression)\n",
    "\n",
    "# Defining the model\n",
    "model = Model(inputRegression, neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 102)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 103       \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 393.1590 - val_loss: 404.9656\n",
      "Epoch 2/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 390.3413 - val_loss: 414.2190\n",
      "Epoch 3/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 387.6356 - val_loss: 423.8359\n",
      "Epoch 4/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 384.9448 - val_loss: 433.7857\n",
      "Epoch 5/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 382.1192 - val_loss: 443.2776\n",
      "Epoch 6/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 379.4421 - val_loss: 453.1030\n",
      "Epoch 7/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 376.7922 - val_loss: 462.5509\n",
      "Epoch 8/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 373.9906 - val_loss: 471.4124\n",
      "Epoch 9/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 371.3518 - val_loss: 480.9796\n",
      "Epoch 10/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 368.6016 - val_loss: 490.3465\n",
      "Epoch 11/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 365.8983 - val_loss: 499.7122\n",
      "Epoch 12/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 363.2323 - val_loss: 508.8301\n",
      "Epoch 13/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 360.6951 - val_loss: 518.2979\n",
      "Epoch 14/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 357.9507 - val_loss: 527.0615\n",
      "Epoch 15/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 355.3929 - val_loss: 536.4041\n",
      "Epoch 16/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 352.8049 - val_loss: 545.5719\n",
      "Epoch 17/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 350.0872 - val_loss: 554.1202\n",
      "Epoch 18/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 347.6037 - val_loss: 563.4127\n",
      "Epoch 19/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 344.8482 - val_loss: 571.7663\n",
      "Epoch 20/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 342.4349 - val_loss: 581.3292\n",
      "Epoch 21/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 339.7329 - val_loss: 590.0175\n",
      "Epoch 22/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 337.0823 - val_loss: 598.4824\n",
      "Epoch 23/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 334.5299 - val_loss: 607.4585\n",
      "Epoch 24/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 331.9563 - val_loss: 615.9149\n",
      "Epoch 25/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 329.5302 - val_loss: 624.1113\n",
      "Epoch 26/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 327.1165 - val_loss: 632.3411\n",
      "Epoch 27/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 324.7006 - val_loss: 640.3636\n",
      "Epoch 28/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 322.2966 - val_loss: 648.0928\n",
      "Epoch 29/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 319.9583 - val_loss: 656.4106\n",
      "Epoch 30/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 317.5990 - val_loss: 664.9236\n",
      "Epoch 31/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 315.1203 - val_loss: 672.8967\n",
      "Epoch 32/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 312.7133 - val_loss: 680.5360\n",
      "Epoch 33/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 310.4290 - val_loss: 688.3057\n",
      "Epoch 34/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.1096 - val_loss: 695.4998\n",
      "Epoch 35/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 305.8437 - val_loss: 702.6822\n",
      "Epoch 36/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 303.6001 - val_loss: 710.3943\n",
      "Epoch 37/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 301.3091 - val_loss: 718.4058\n",
      "Epoch 38/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 298.9684 - val_loss: 726.2686\n",
      "Epoch 39/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 296.6715 - val_loss: 734.2072\n",
      "Epoch 40/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.4031 - val_loss: 742.4238\n",
      "Epoch 41/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 292.0102 - val_loss: 749.6934\n",
      "Epoch 42/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 289.7428 - val_loss: 757.2643\n",
      "Epoch 43/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 287.4557 - val_loss: 765.0765\n",
      "Epoch 44/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 285.1575 - val_loss: 772.7231\n",
      "Epoch 45/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.8833 - val_loss: 780.7407\n",
      "Epoch 46/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.5096 - val_loss: 788.4797\n",
      "Epoch 47/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.1407 - val_loss: 795.4152\n",
      "Epoch 48/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 275.9070 - val_loss: 803.3556\n",
      "Epoch 49/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 273.5957 - val_loss: 811.0106\n",
      "Epoch 50/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 271.2733 - val_loss: 818.6732\n",
      "Epoch 51/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.9605 - val_loss: 826.5159\n",
      "Epoch 52/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 266.6868 - val_loss: 833.7321\n",
      "Epoch 53/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 264.4487 - val_loss: 841.0176\n",
      "Epoch 54/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 262.3181 - val_loss: 848.8306\n",
      "Epoch 55/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 260.0455 - val_loss: 856.1696\n",
      "Epoch 56/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 257.7611 - val_loss: 863.1688\n",
      "Epoch 57/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.6237 - val_loss: 870.5379\n",
      "Epoch 58/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 253.3292 - val_loss: 877.5980\n",
      "Epoch 59/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 251.1980 - val_loss: 885.3722\n",
      "Epoch 60/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 248.8837 - val_loss: 892.6193\n",
      "Epoch 61/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 246.6328 - val_loss: 900.0203\n",
      "Epoch 62/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 244.4197 - val_loss: 907.5359\n",
      "Epoch 63/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 242.1917 - val_loss: 915.4468\n",
      "Epoch 64/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 239.8962 - val_loss: 922.9869\n",
      "Epoch 65/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 237.6458 - val_loss: 930.5020\n",
      "Epoch 66/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 235.3972 - val_loss: 938.0531\n",
      "Epoch 67/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.1457 - val_loss: 945.9756\n",
      "Epoch 68/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 230.8131 - val_loss: 953.4402\n",
      "Epoch 69/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 228.6661 - val_loss: 961.4979\n",
      "Epoch 70/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 226.3397 - val_loss: 968.7174\n",
      "Epoch 71/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.2256 - val_loss: 976.0011\n",
      "Epoch 72/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 222.1051 - val_loss: 983.4945\n",
      "Epoch 73/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 219.8557 - val_loss: 990.4538\n",
      "Epoch 74/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 217.7783 - val_loss: 997.7957\n",
      "Epoch 75/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 215.6272 - val_loss: 1004.7629\n",
      "Epoch 76/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 213.4904 - val_loss: 1011.6405\n",
      "Epoch 77/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 211.4086 - val_loss: 1018.8737\n",
      "Epoch 78/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 209.4409 - val_loss: 1026.8547\n",
      "Epoch 79/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 207.1482 - val_loss: 1033.1355\n",
      "Epoch 80/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 205.2002 - val_loss: 1040.1279\n",
      "Epoch 81/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 203.2745 - val_loss: 1047.3655\n",
      "Epoch 82/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 201.2648 - val_loss: 1054.1855\n",
      "Epoch 83/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 199.3053 - val_loss: 1060.6578\n",
      "Epoch 84/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 197.2577 - val_loss: 1067.0333\n",
      "Epoch 85/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 195.4318 - val_loss: 1073.8768\n",
      "Epoch 86/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.3917 - val_loss: 1080.4180\n",
      "Epoch 87/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.4492 - val_loss: 1086.7705\n",
      "Epoch 88/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 189.5216 - val_loss: 1093.5557\n",
      "Epoch 89/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 187.5916 - val_loss: 1100.0361\n",
      "Epoch 90/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 185.5940 - val_loss: 1106.5555\n",
      "Epoch 91/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 183.6881 - val_loss: 1113.1002\n",
      "Epoch 92/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 181.8325 - val_loss: 1119.6222\n",
      "Epoch 93/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 180.0581 - val_loss: 1125.5056\n",
      "Epoch 94/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.3977 - val_loss: 1131.6564\n",
      "Epoch 95/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 176.6092 - val_loss: 1137.3318\n",
      "Epoch 96/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 174.9751 - val_loss: 1143.3752\n",
      "Epoch 97/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 173.2513 - val_loss: 1149.4901\n",
      "Epoch 98/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 171.5011 - val_loss: 1155.2302\n",
      "Epoch 99/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 169.7741 - val_loss: 1160.5553\n",
      "Epoch 100/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 168.1364 - val_loss: 1166.7410\n",
      "Epoch 101/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 166.4104 - val_loss: 1172.4463\n",
      "Epoch 102/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 164.7431 - val_loss: 1178.3558\n",
      "Epoch 103/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 163.1042 - val_loss: 1184.8333\n",
      "Epoch 104/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 161.2790 - val_loss: 1190.2191\n",
      "Epoch 105/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 159.7005 - val_loss: 1196.3152\n",
      "Epoch 106/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.9863 - val_loss: 1202.3058\n",
      "Epoch 107/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 156.2839 - val_loss: 1207.7417\n",
      "Epoch 108/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 154.6435 - val_loss: 1213.5730\n",
      "Epoch 109/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 152.9756 - val_loss: 1219.0837\n",
      "Epoch 110/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 151.2755 - val_loss: 1224.7947\n",
      "Epoch 111/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 149.6955 - val_loss: 1230.8223\n",
      "Epoch 112/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 147.9488 - val_loss: 1236.6892\n",
      "Epoch 113/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 146.2974 - val_loss: 1242.3285\n",
      "Epoch 114/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 144.5632 - val_loss: 1247.7676\n",
      "Epoch 115/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 143.0595 - val_loss: 1254.2380\n",
      "Epoch 116/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 141.4011 - val_loss: 1259.9440\n",
      "Epoch 117/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 139.8537 - val_loss: 1265.4850\n",
      "Epoch 118/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 138.2946 - val_loss: 1270.6315\n",
      "Epoch 119/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 136.8285 - val_loss: 1275.6550\n",
      "Epoch 120/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 135.2626 - val_loss: 1280.2094\n",
      "Epoch 121/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 133.8970 - val_loss: 1285.2072\n",
      "Epoch 122/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 132.5418 - val_loss: 1289.8840\n",
      "Epoch 123/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 131.2539 - val_loss: 1294.7362\n",
      "Epoch 124/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 129.9916 - val_loss: 1299.6051\n",
      "Epoch 125/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.7407 - val_loss: 1303.9539\n",
      "Epoch 126/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 127.6080 - val_loss: 1308.5062\n",
      "Epoch 127/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 126.4562 - val_loss: 1312.8419\n",
      "Epoch 128/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 125.3754 - val_loss: 1317.2229\n",
      "Epoch 129/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 124.2711 - val_loss: 1321.1058\n",
      "Epoch 130/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.2620 - val_loss: 1324.6447\n",
      "Epoch 131/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 122.2418 - val_loss: 1328.1799\n",
      "Epoch 132/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 121.3474 - val_loss: 1331.5979\n",
      "Epoch 133/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.4671 - val_loss: 1334.5364\n",
      "Epoch 134/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 119.6807 - val_loss: 1337.8700\n",
      "Epoch 135/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 118.8804 - val_loss: 1340.4631\n",
      "Epoch 136/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 118.0744 - val_loss: 1342.2679\n",
      "Epoch 137/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.3996 - val_loss: 1344.6027\n",
      "Epoch 138/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 116.7090 - val_loss: 1347.2994\n",
      "Epoch 139/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 115.9930 - val_loss: 1349.8641\n",
      "Epoch 140/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.2126 - val_loss: 1352.2360\n",
      "Epoch 141/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 114.5329 - val_loss: 1355.1674\n",
      "Epoch 142/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.8293 - val_loss: 1357.7024\n",
      "Epoch 143/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.1376 - val_loss: 1360.2772\n",
      "Epoch 144/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 112.4576 - val_loss: 1362.3549\n",
      "Epoch 145/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 111.8364 - val_loss: 1364.4883\n",
      "Epoch 146/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 111.2825 - val_loss: 1366.9469\n",
      "Epoch 147/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 110.6977 - val_loss: 1368.7324\n",
      "Epoch 148/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 110.1377 - val_loss: 1369.9658\n",
      "Epoch 149/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.6391 - val_loss: 1371.6926\n",
      "Epoch 150/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.1083 - val_loss: 1373.2222\n",
      "Epoch 151/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 108.6203 - val_loss: 1374.7477\n",
      "Epoch 152/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.1167 - val_loss: 1376.3271\n",
      "Epoch 153/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 107.5979 - val_loss: 1377.6223\n",
      "Epoch 154/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 107.1349 - val_loss: 1378.8984\n",
      "Epoch 155/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.6821 - val_loss: 1380.2694\n",
      "Epoch 156/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 106.2494 - val_loss: 1382.1317\n",
      "Epoch 157/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.8249 - val_loss: 1383.9694\n",
      "Epoch 158/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 105.3700 - val_loss: 1384.7351\n",
      "Epoch 159/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.9997 - val_loss: 1385.2545\n",
      "Epoch 160/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 104.6234 - val_loss: 1385.8083\n",
      "Epoch 161/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 104.2556 - val_loss: 1386.8379\n",
      "Epoch 162/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 103.8810 - val_loss: 1387.8840\n",
      "Epoch 163/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 103.4835 - val_loss: 1388.5946\n",
      "Epoch 164/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 103.1349 - val_loss: 1389.2346\n",
      "Epoch 165/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.7875 - val_loss: 1389.6885\n",
      "Epoch 166/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 102.4512 - val_loss: 1390.0027\n",
      "Epoch 167/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 102.1067 - val_loss: 1389.8177\n",
      "Epoch 168/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 101.8354 - val_loss: 1390.5757\n",
      "Epoch 169/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.4850 - val_loss: 1390.5457\n",
      "Epoch 170/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 101.2010 - val_loss: 1390.6412\n",
      "Epoch 171/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.8975 - val_loss: 1390.8086\n",
      "Epoch 172/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6105 - val_loss: 1390.8318\n",
      "Epoch 173/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 100.3257 - val_loss: 1390.7253\n",
      "Epoch 174/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 100.0764 - val_loss: 1390.5999\n",
      "Epoch 175/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 99.8057 - val_loss: 1390.0312\n",
      "Epoch 176/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.5557 - val_loss: 1389.9916\n",
      "Epoch 177/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 99.2938 - val_loss: 1389.7465\n",
      "Epoch 178/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 99.0479 - val_loss: 1389.6171\n",
      "Epoch 179/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.7867 - val_loss: 1388.8223\n",
      "Epoch 180/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 98.5644 - val_loss: 1388.4803\n",
      "Epoch 181/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.3375 - val_loss: 1387.8413\n",
      "Epoch 182/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.1085 - val_loss: 1387.1812\n",
      "Epoch 183/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.8988 - val_loss: 1387.3010\n",
      "Epoch 184/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.6822 - val_loss: 1386.4098\n",
      "Epoch 185/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 97.4577 - val_loss: 1385.7018\n",
      "Epoch 186/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 97.2594 - val_loss: 1384.8712\n",
      "Epoch 187/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 97.0643 - val_loss: 1383.7604\n",
      "Epoch 188/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.8910 - val_loss: 1382.9392\n",
      "Epoch 189/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 96.7253 - val_loss: 1381.6029\n",
      "Epoch 190/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 96.5411 - val_loss: 1379.4935\n",
      "Epoch 191/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 96.3903 - val_loss: 1376.3015\n",
      "Epoch 192/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 96.2095 - val_loss: 1374.5676\n",
      "Epoch 193/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 96.0381 - val_loss: 1372.2444\n",
      "Epoch 194/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 95.8796 - val_loss: 1370.0521\n",
      "Epoch 195/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 95.7214 - val_loss: 1367.7605\n",
      "Epoch 196/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.5610 - val_loss: 1365.4135\n",
      "Epoch 197/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 95.3900 - val_loss: 1363.7281\n",
      "Epoch 198/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 95.2276 - val_loss: 1362.1146\n",
      "Epoch 199/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.0811 - val_loss: 1360.1106\n",
      "Epoch 200/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 94.9142 - val_loss: 1357.8369\n",
      "Epoch 201/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.7507 - val_loss: 1355.5406\n",
      "Epoch 202/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 94.6164 - val_loss: 1352.5295\n",
      "Epoch 203/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 94.4345 - val_loss: 1350.2419\n",
      "Epoch 204/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 94.2910 - val_loss: 1347.9647\n",
      "Epoch 205/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 94.1238 - val_loss: 1345.9437\n",
      "Epoch 206/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 93.9750 - val_loss: 1344.3275\n",
      "Epoch 207/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.8269 - val_loss: 1342.6078\n",
      "Epoch 208/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.6722 - val_loss: 1339.6852\n",
      "Epoch 209/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 93.5142 - val_loss: 1337.2113\n",
      "Epoch 210/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 93.3559 - val_loss: 1334.9762\n",
      "Epoch 211/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.2008 - val_loss: 1332.9391\n",
      "Epoch 212/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 93.0591 - val_loss: 1331.1172\n",
      "Epoch 213/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 92.9113 - val_loss: 1328.3276\n",
      "Epoch 214/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 92.7589 - val_loss: 1325.7063\n",
      "Epoch 215/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 92.5977 - val_loss: 1324.3390\n",
      "Epoch 216/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 92.4530 - val_loss: 1321.7349\n",
      "Epoch 217/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.3055 - val_loss: 1319.3541\n",
      "Epoch 218/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 92.1381 - val_loss: 1317.6415\n",
      "Epoch 219/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 91.9900 - val_loss: 1315.8574\n",
      "Epoch 220/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.8444 - val_loss: 1313.8070\n",
      "Epoch 221/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.6900 - val_loss: 1311.2830\n",
      "Epoch 222/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 91.5513 - val_loss: 1308.3776\n",
      "Epoch 223/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 91.3951 - val_loss: 1306.1548\n",
      "Epoch 224/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 91.2413 - val_loss: 1303.8650\n",
      "Epoch 225/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 91.0894 - val_loss: 1301.6888\n",
      "Epoch 226/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 90.9433 - val_loss: 1299.7483\n",
      "Epoch 227/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.7845 - val_loss: 1298.1077\n",
      "Epoch 228/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 90.6472 - val_loss: 1295.7140\n",
      "Epoch 229/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.5041 - val_loss: 1293.4863\n",
      "Epoch 230/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.3478 - val_loss: 1292.1287\n",
      "Epoch 231/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 90.1958 - val_loss: 1289.9137\n",
      "Epoch 232/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 90.0405 - val_loss: 1287.6215\n",
      "Epoch 233/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 89.9038 - val_loss: 1284.9379\n",
      "Epoch 234/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.7327 - val_loss: 1282.5417\n",
      "Epoch 235/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.5920 - val_loss: 1279.9183\n",
      "Epoch 236/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 89.4473 - val_loss: 1277.3174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 89.2896 - val_loss: 1275.4486\n",
      "Epoch 238/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.1444 - val_loss: 1273.9578\n",
      "Epoch 239/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.9908 - val_loss: 1272.2053\n",
      "Epoch 240/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 88.8567 - val_loss: 1269.3885\n",
      "Epoch 241/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.6875 - val_loss: 1267.4031\n",
      "Epoch 242/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 88.5500 - val_loss: 1264.8569\n",
      "Epoch 243/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 88.4062 - val_loss: 1263.2727\n",
      "Epoch 244/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 88.2520 - val_loss: 1260.5768\n",
      "Epoch 245/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.1028 - val_loss: 1257.8729\n",
      "Epoch 246/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.9481 - val_loss: 1255.6609\n",
      "Epoch 247/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 87.7996 - val_loss: 1253.4542\n",
      "Epoch 248/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.6610 - val_loss: 1251.7841\n",
      "Epoch 249/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.5331 - val_loss: 1248.6354\n",
      "Epoch 250/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 87.3647 - val_loss: 1246.5629\n",
      "Epoch 251/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 87.2135 - val_loss: 1244.8990\n",
      "Epoch 252/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.0784 - val_loss: 1243.3214\n",
      "Epoch 253/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 86.9362 - val_loss: 1241.2994\n",
      "Epoch 254/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.7802 - val_loss: 1239.4664\n",
      "Epoch 255/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 86.6585 - val_loss: 1236.7321\n",
      "Epoch 256/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 86.4930 - val_loss: 1235.0576\n",
      "Epoch 257/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 86.3540 - val_loss: 1233.6356\n",
      "Epoch 258/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 86.2128 - val_loss: 1231.6194\n",
      "Epoch 259/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.0750 - val_loss: 1229.7703\n",
      "Epoch 260/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.9300 - val_loss: 1228.0865\n",
      "Epoch 261/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.7845 - val_loss: 1225.9901\n",
      "Epoch 262/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.6445 - val_loss: 1224.1238\n",
      "Epoch 263/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.5001 - val_loss: 1221.6887\n",
      "Epoch 264/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.3507 - val_loss: 1219.9166\n",
      "Epoch 265/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.2170 - val_loss: 1217.6418\n",
      "Epoch 266/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.0901 - val_loss: 1214.5677\n",
      "Epoch 267/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 84.9184 - val_loss: 1212.6179\n",
      "Epoch 268/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 84.7845 - val_loss: 1210.5680\n",
      "Epoch 269/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.6348 - val_loss: 1208.4130\n",
      "Epoch 270/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 84.4985 - val_loss: 1206.4832\n",
      "Epoch 271/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.3500 - val_loss: 1203.9255\n",
      "Epoch 272/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 84.2214 - val_loss: 1200.8083\n",
      "Epoch 273/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 84.0641 - val_loss: 1198.1768\n",
      "Epoch 274/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 83.9174 - val_loss: 1196.0198\n",
      "Epoch 275/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 83.7718 - val_loss: 1194.1478\n",
      "Epoch 276/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 83.6430 - val_loss: 1192.3557\n",
      "Epoch 277/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 83.4881 - val_loss: 1189.9062\n",
      "Epoch 278/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 83.3447 - val_loss: 1187.2985\n",
      "Epoch 279/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.2088 - val_loss: 1184.6620\n",
      "Epoch 280/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.0634 - val_loss: 1182.6359\n",
      "Epoch 281/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 82.9074 - val_loss: 1180.1268\n",
      "Epoch 282/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.7813 - val_loss: 1177.7747\n",
      "Epoch 283/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.6303 - val_loss: 1175.1139\n",
      "Epoch 284/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 82.4897 - val_loss: 1172.7871\n",
      "Epoch 285/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 82.3461 - val_loss: 1171.3380\n",
      "Epoch 286/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 82.2028 - val_loss: 1168.7351\n",
      "Epoch 287/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.0519 - val_loss: 1166.9147\n",
      "Epoch 288/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 81.9215 - val_loss: 1164.5546\n",
      "Epoch 289/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.8029 - val_loss: 1161.9541\n",
      "Epoch 290/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.6425 - val_loss: 1161.3373\n",
      "Epoch 291/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.5022 - val_loss: 1159.4666\n",
      "Epoch 292/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.3656 - val_loss: 1158.4304\n",
      "Epoch 293/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 81.2256 - val_loss: 1155.2883\n",
      "Epoch 294/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 81.0764 - val_loss: 1152.8875\n",
      "Epoch 295/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 80.9373 - val_loss: 1151.3529\n",
      "Epoch 296/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 80.7878 - val_loss: 1149.3340\n",
      "Epoch 297/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 80.6489 - val_loss: 1146.9894\n",
      "Epoch 298/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 80.5008 - val_loss: 1144.4500\n",
      "Epoch 299/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 80.3783 - val_loss: 1141.4962\n",
      "Epoch 300/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 80.2147 - val_loss: 1139.7501\n",
      "Epoch 301/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 80.0836 - val_loss: 1137.5906\n",
      "Epoch 302/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 79.9439 - val_loss: 1135.6570\n",
      "Epoch 303/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 79.7966 - val_loss: 1134.1240\n",
      "Epoch 304/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 79.6544 - val_loss: 1132.0256\n",
      "Epoch 305/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.5146 - val_loss: 1129.7725\n",
      "Epoch 306/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 79.3698 - val_loss: 1127.2263\n",
      "Epoch 307/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 79.2257 - val_loss: 1125.0652\n",
      "Epoch 308/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 79.0900 - val_loss: 1122.7750\n",
      "Epoch 309/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 78.9447 - val_loss: 1121.4993\n",
      "Epoch 310/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 78.8056 - val_loss: 1119.7334\n",
      "Epoch 311/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.6667 - val_loss: 1117.2729\n",
      "Epoch 312/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 78.5376 - val_loss: 1114.3082\n",
      "Epoch 313/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 78.3880 - val_loss: 1112.8239\n",
      "Epoch 314/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 78.2596 - val_loss: 1109.9049\n",
      "Epoch 315/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 78.1181 - val_loss: 1108.5144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 77.9771 - val_loss: 1106.2419\n",
      "Epoch 317/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 77.8253 - val_loss: 1104.7676\n",
      "Epoch 318/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.6984 - val_loss: 1102.9974\n",
      "Epoch 319/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 77.5589 - val_loss: 1101.5524\n",
      "Epoch 320/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 77.4214 - val_loss: 1098.8191\n",
      "Epoch 321/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 77.2751 - val_loss: 1096.8204\n",
      "Epoch 322/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 77.1531 - val_loss: 1094.1550\n",
      "Epoch 323/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 77.0080 - val_loss: 1092.6669\n",
      "Epoch 324/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.8649 - val_loss: 1090.2029\n",
      "Epoch 325/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 76.7514 - val_loss: 1087.3147\n",
      "Epoch 326/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 76.5789 - val_loss: 1085.8168\n",
      "Epoch 327/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 76.4560 - val_loss: 1084.3330\n",
      "Epoch 328/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 76.3013 - val_loss: 1082.4119\n",
      "Epoch 329/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 76.1680 - val_loss: 1080.0399\n",
      "Epoch 330/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 76.0314 - val_loss: 1077.8445\n",
      "Epoch 331/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 75.8895 - val_loss: 1076.7825\n",
      "Epoch 332/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 75.7534 - val_loss: 1075.0198\n",
      "Epoch 333/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.6204 - val_loss: 1071.9211\n",
      "Epoch 334/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 75.4762 - val_loss: 1069.6649\n",
      "Epoch 335/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.3353 - val_loss: 1067.4579\n",
      "Epoch 336/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 75.1977 - val_loss: 1065.5990\n",
      "Epoch 337/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.0621 - val_loss: 1063.7574\n",
      "Epoch 338/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 74.9240 - val_loss: 1061.9569\n",
      "Epoch 339/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 74.7971 - val_loss: 1060.2726\n",
      "Epoch 340/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 74.6667 - val_loss: 1056.9978\n",
      "Epoch 341/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 74.5240 - val_loss: 1054.2397\n",
      "Epoch 342/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 74.3699 - val_loss: 1052.8442\n",
      "Epoch 343/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 74.2317 - val_loss: 1051.8584\n",
      "Epoch 344/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 74.0931 - val_loss: 1050.3572\n",
      "Epoch 345/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.9628 - val_loss: 1048.8307\n",
      "Epoch 346/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.8303 - val_loss: 1046.5710\n",
      "Epoch 347/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.6922 - val_loss: 1044.9611\n",
      "Epoch 348/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.5820 - val_loss: 1042.2289\n",
      "Epoch 349/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.4291 - val_loss: 1041.0015\n",
      "Epoch 350/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.3093 - val_loss: 1038.2490\n",
      "Epoch 351/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.1534 - val_loss: 1036.7806\n",
      "Epoch 352/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.0230 - val_loss: 1034.6102\n",
      "Epoch 353/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.8889 - val_loss: 1032.7219\n",
      "Epoch 354/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 72.7495 - val_loss: 1031.2465\n",
      "Epoch 355/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.6114 - val_loss: 1028.6628\n",
      "Epoch 356/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 72.4787 - val_loss: 1025.8879\n",
      "Epoch 357/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 72.3348 - val_loss: 1023.9432\n",
      "Epoch 358/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 72.2334 - val_loss: 1020.9232\n",
      "Epoch 359/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 72.0677 - val_loss: 1018.9888\n",
      "Epoch 360/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.9301 - val_loss: 1017.1644\n",
      "Epoch 361/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.8009 - val_loss: 1015.6012\n",
      "Epoch 362/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 71.6620 - val_loss: 1014.1348\n",
      "Epoch 363/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.5334 - val_loss: 1011.7542\n",
      "Epoch 364/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 71.4058 - val_loss: 1009.6125\n",
      "Epoch 365/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.2610 - val_loss: 1007.9574\n",
      "Epoch 366/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 71.1406 - val_loss: 1005.3478\n",
      "Epoch 367/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.0000 - val_loss: 1003.2123\n",
      "Epoch 368/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 70.8650 - val_loss: 1001.2087\n",
      "Epoch 369/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 70.7303 - val_loss: 999.6390\n",
      "Epoch 370/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.6024 - val_loss: 996.6097\n",
      "Epoch 371/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.4826 - val_loss: 993.7936\n",
      "Epoch 372/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 70.3444 - val_loss: 993.3999\n",
      "Epoch 373/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 70.1920 - val_loss: 990.4694\n",
      "Epoch 374/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 70.0469 - val_loss: 987.4371\n",
      "Epoch 375/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 69.9110 - val_loss: 985.0317\n",
      "Epoch 376/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 69.7590 - val_loss: 983.6614\n",
      "Epoch 377/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 69.6351 - val_loss: 982.2576\n",
      "Epoch 378/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 69.4965 - val_loss: 979.8587\n",
      "Epoch 379/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 69.3730 - val_loss: 978.3563\n",
      "Epoch 380/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 69.2240 - val_loss: 975.7932\n",
      "Epoch 381/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 69.0964 - val_loss: 972.6179\n",
      "Epoch 382/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 68.9705 - val_loss: 971.1674\n",
      "Epoch 383/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 68.8241 - val_loss: 968.5284\n",
      "Epoch 384/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 68.6839 - val_loss: 967.0244\n",
      "Epoch 385/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 68.5581 - val_loss: 965.3275\n",
      "Epoch 386/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 68.4260 - val_loss: 962.5218\n",
      "Epoch 387/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 68.2816 - val_loss: 960.3810\n",
      "Epoch 388/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 68.1471 - val_loss: 958.5056\n",
      "Epoch 389/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 68.0131 - val_loss: 956.2865\n",
      "Epoch 390/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 67.8817 - val_loss: 954.5295\n",
      "Epoch 391/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 67.7446 - val_loss: 953.0199\n",
      "Epoch 392/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 67.6211 - val_loss: 951.4769\n",
      "Epoch 393/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 67.4869 - val_loss: 949.2057\n",
      "Epoch 394/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 67.3542 - val_loss: 946.7043\n",
      "Epoch 395/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 67.2154 - val_loss: 944.5213\n",
      "Epoch 396/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 67.0841 - val_loss: 942.4893\n",
      "Epoch 397/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 66.9536 - val_loss: 940.0055\n",
      "Epoch 398/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 66.8165 - val_loss: 938.0672\n",
      "Epoch 399/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 66.6830 - val_loss: 936.2814\n",
      "Epoch 400/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 66.5537 - val_loss: 933.8105\n",
      "Epoch 401/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 66.4160 - val_loss: 932.3362\n",
      "Epoch 402/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 66.2735 - val_loss: 930.8005\n",
      "Epoch 403/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 66.1614 - val_loss: 928.4494\n",
      "Epoch 404/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 66.0126 - val_loss: 927.2052\n",
      "Epoch 405/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 65.8880 - val_loss: 925.0250\n",
      "Epoch 406/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 65.7794 - val_loss: 921.9725\n",
      "Epoch 407/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 65.6252 - val_loss: 919.9230\n",
      "Epoch 408/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.4864 - val_loss: 918.6902\n",
      "Epoch 409/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.3538 - val_loss: 916.2111\n",
      "Epoch 410/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 65.2173 - val_loss: 914.1024\n",
      "Epoch 411/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.0966 - val_loss: 912.5697\n",
      "Epoch 412/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 64.9641 - val_loss: 911.0311\n",
      "Epoch 413/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 64.8327 - val_loss: 906.9233\n",
      "Epoch 414/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 64.6853 - val_loss: 905.1967\n",
      "Epoch 415/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 64.5367 - val_loss: 902.7240\n",
      "Epoch 416/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 64.4226 - val_loss: 899.9802\n",
      "Epoch 417/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 64.2812 - val_loss: 899.4949\n",
      "Epoch 418/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 64.1397 - val_loss: 897.3940\n",
      "Epoch 419/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 63.9999 - val_loss: 895.9410\n",
      "Epoch 420/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 63.8900 - val_loss: 893.5018\n",
      "Epoch 421/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 63.7477 - val_loss: 892.1736\n",
      "Epoch 422/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 63.6215 - val_loss: 888.9401\n",
      "Epoch 423/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 63.4654 - val_loss: 886.7203\n",
      "Epoch 424/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 63.3577 - val_loss: 884.1479\n",
      "Epoch 425/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 63.2201 - val_loss: 883.4855\n",
      "Epoch 426/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 63.0675 - val_loss: 881.0948\n",
      "Epoch 427/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.9437 - val_loss: 878.7907\n",
      "Epoch 428/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 62.8179 - val_loss: 876.0530\n",
      "Epoch 429/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 62.6772 - val_loss: 873.9885\n",
      "Epoch 430/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 62.5389 - val_loss: 872.4466\n",
      "Epoch 431/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.4206 - val_loss: 870.0966\n",
      "Epoch 432/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.2773 - val_loss: 869.2897\n",
      "Epoch 433/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.1478 - val_loss: 867.1412\n",
      "Epoch 434/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.0275 - val_loss: 865.7660\n",
      "Epoch 435/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 61.8874 - val_loss: 863.2070\n",
      "Epoch 436/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 61.7988 - val_loss: 859.5197\n",
      "Epoch 437/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 61.6211 - val_loss: 858.6794\n",
      "Epoch 438/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 61.4939 - val_loss: 857.5101\n",
      "Epoch 439/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 61.3569 - val_loss: 854.1544\n",
      "Epoch 440/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 61.2306 - val_loss: 852.1987\n",
      "Epoch 441/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 61.0911 - val_loss: 849.5553\n",
      "Epoch 442/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 60.9590 - val_loss: 847.4303\n",
      "Epoch 443/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 60.8443 - val_loss: 845.1844\n",
      "Epoch 444/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 60.6991 - val_loss: 843.7432\n",
      "Epoch 445/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 60.5678 - val_loss: 842.5057\n",
      "Epoch 446/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 60.4287 - val_loss: 840.7194\n",
      "Epoch 447/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 60.3232 - val_loss: 839.8584\n",
      "Epoch 448/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 60.1808 - val_loss: 837.4295\n",
      "Epoch 449/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 60.0968 - val_loss: 836.8336\n",
      "Epoch 450/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 59.9053 - val_loss: 832.6232\n",
      "Epoch 451/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 59.7774 - val_loss: 828.9647\n",
      "Epoch 452/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 59.6645 - val_loss: 825.5343\n",
      "Epoch 453/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 59.5209 - val_loss: 823.9406\n",
      "Epoch 454/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 59.3840 - val_loss: 822.4991\n",
      "Epoch 455/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 59.2505 - val_loss: 821.4762\n",
      "Epoch 456/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 59.1153 - val_loss: 819.7933\n",
      "Epoch 457/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 58.9921 - val_loss: 818.4196\n",
      "Epoch 458/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 58.8614 - val_loss: 816.5018\n",
      "Epoch 459/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 58.7398 - val_loss: 813.5587\n",
      "Epoch 460/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 58.5923 - val_loss: 811.6220\n",
      "Epoch 461/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 58.4792 - val_loss: 810.2520\n",
      "Epoch 462/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 58.3447 - val_loss: 808.5922\n",
      "Epoch 463/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 58.2057 - val_loss: 806.4721\n",
      "Epoch 464/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 58.0734 - val_loss: 803.9141\n",
      "Epoch 465/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 57.9398 - val_loss: 801.4539\n",
      "Epoch 466/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 57.8075 - val_loss: 798.9176\n",
      "Epoch 467/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 57.6867 - val_loss: 797.3982\n",
      "Epoch 468/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 57.5333 - val_loss: 795.1856\n",
      "Epoch 469/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 57.4202 - val_loss: 792.4424\n",
      "Epoch 470/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 57.2684 - val_loss: 791.2994\n",
      "Epoch 471/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 57.1382 - val_loss: 790.1112\n",
      "Epoch 472/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 57.0128 - val_loss: 786.9721\n",
      "Epoch 473/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 56.8625 - val_loss: 785.4484\n",
      "Epoch 474/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 56.7405 - val_loss: 783.0234\n",
      "Epoch 475/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 56.6177 - val_loss: 780.5139\n",
      "Epoch 476/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 56.4709 - val_loss: 779.2878\n",
      "Epoch 477/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 56.3426 - val_loss: 777.4048\n",
      "Epoch 478/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 56.2214 - val_loss: 775.2094\n",
      "Epoch 479/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 56.0969 - val_loss: 774.1786\n",
      "Epoch 480/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 55.9734 - val_loss: 772.0554\n",
      "Epoch 481/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 55.8250 - val_loss: 768.9772\n",
      "Epoch 482/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 55.7019 - val_loss: 767.4425\n",
      "Epoch 483/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 55.5765 - val_loss: 764.5100\n",
      "Epoch 484/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 55.4596 - val_loss: 763.4388\n",
      "Epoch 485/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 55.3819 - val_loss: 763.5834\n",
      "Epoch 486/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 55.2838 - val_loss: 762.5417\n",
      "Epoch 487/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 55.1776 - val_loss: 760.5548\n",
      "Epoch 488/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 55.0856 - val_loss: 757.8461\n",
      "Epoch 489/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.9834 - val_loss: 755.8503\n",
      "Epoch 490/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.9043 - val_loss: 753.9906\n",
      "Epoch 491/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.8166 - val_loss: 753.2226\n",
      "Epoch 492/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 54.7159 - val_loss: 751.8553\n",
      "Epoch 493/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.6456 - val_loss: 751.4095\n",
      "Epoch 494/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 54.5408 - val_loss: 749.4427\n",
      "Epoch 495/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.4633 - val_loss: 747.1288\n",
      "Epoch 496/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.3592 - val_loss: 746.0736\n",
      "Epoch 497/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.2620 - val_loss: 745.8098\n",
      "Epoch 498/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.1873 - val_loss: 744.7155\n",
      "Epoch 499/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 54.0896 - val_loss: 742.2654\n",
      "Epoch 500/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 53.9915 - val_loss: 740.7480\n",
      "Epoch 501/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 53.9104 - val_loss: 738.4092\n",
      "Epoch 502/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.8081 - val_loss: 736.3746\n",
      "Epoch 503/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.7151 - val_loss: 735.2147\n",
      "Epoch 504/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.6236 - val_loss: 733.1195\n",
      "Epoch 505/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.5289 - val_loss: 731.2482\n",
      "Epoch 506/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.4442 - val_loss: 730.4222\n",
      "Epoch 507/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.3429 - val_loss: 729.5143\n",
      "Epoch 508/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 53.2616 - val_loss: 727.2958\n",
      "Epoch 509/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.1673 - val_loss: 726.8821\n",
      "Epoch 510/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 53.0758 - val_loss: 724.1212\n",
      "Epoch 511/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.9737 - val_loss: 722.5702\n",
      "Epoch 512/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 52.8859 - val_loss: 721.4921\n",
      "Epoch 513/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.7895 - val_loss: 719.3937\n",
      "Epoch 514/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 52.6978 - val_loss: 717.2501\n",
      "Epoch 515/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 52.6123 - val_loss: 714.9546\n",
      "Epoch 516/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.5142 - val_loss: 713.0677\n",
      "Epoch 517/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.4158 - val_loss: 711.3983\n",
      "Epoch 518/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.3288 - val_loss: 709.7885\n",
      "Epoch 519/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.2451 - val_loss: 707.5827\n",
      "Epoch 520/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 52.1475 - val_loss: 706.2489\n",
      "Epoch 521/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.0583 - val_loss: 704.7584\n",
      "Epoch 522/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 51.9638 - val_loss: 704.5332\n",
      "Epoch 523/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 51.8720 - val_loss: 703.3040\n",
      "Epoch 524/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 51.7708 - val_loss: 701.9487\n",
      "Epoch 525/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 51.6792 - val_loss: 700.8425\n",
      "Epoch 526/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 51.6089 - val_loss: 699.9769\n",
      "Epoch 527/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 51.5411 - val_loss: 696.4759\n",
      "Epoch 528/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 51.4064 - val_loss: 695.5379\n",
      "Epoch 529/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 51.3221 - val_loss: 694.7543\n",
      "Epoch 530/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 51.2414 - val_loss: 692.7448\n",
      "Epoch 531/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 51.1463 - val_loss: 691.1850\n",
      "Epoch 532/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 51.0683 - val_loss: 689.8071\n",
      "Epoch 533/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 50.9903 - val_loss: 688.7531\n",
      "Epoch 534/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 50.9333 - val_loss: 687.7815\n",
      "Epoch 535/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 50.8807 - val_loss: 684.2548\n",
      "Epoch 536/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 50.7507 - val_loss: 682.9825\n",
      "Epoch 537/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 50.6735 - val_loss: 682.1487\n",
      "Epoch 538/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 50.5946 - val_loss: 681.3829\n",
      "Epoch 539/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 50.5088 - val_loss: 678.4190\n",
      "Epoch 540/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 50.4300 - val_loss: 676.6034\n",
      "Epoch 541/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 50.3455 - val_loss: 675.0577\n",
      "Epoch 542/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 50.2729 - val_loss: 673.6933\n",
      "Epoch 543/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 50.2052 - val_loss: 672.4945\n",
      "Epoch 544/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 50.1477 - val_loss: 672.9077\n",
      "Epoch 545/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 50.0544 - val_loss: 670.3726\n",
      "Epoch 546/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.9704 - val_loss: 667.2041\n",
      "Epoch 547/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.9089 - val_loss: 667.0853\n",
      "Epoch 548/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.8126 - val_loss: 663.7311\n",
      "Epoch 549/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.7322 - val_loss: 663.1635\n",
      "Epoch 550/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.6394 - val_loss: 661.3991\n",
      "Epoch 551/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.5502 - val_loss: 660.2796\n",
      "Epoch 552/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.4824 - val_loss: 658.7274\n",
      "Epoch 553/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 49.4164 - val_loss: 658.3004\n",
      "Epoch 554/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.3751 - val_loss: 654.7337\n",
      "Epoch 555/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.2381 - val_loss: 653.1104\n",
      "Epoch 556/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.1853 - val_loss: 651.3556\n",
      "Epoch 557/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.1106 - val_loss: 649.4373\n",
      "Epoch 558/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.0021 - val_loss: 649.9855\n",
      "Epoch 559/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.9268 - val_loss: 648.7410\n",
      "Epoch 560/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.8598 - val_loss: 647.0324\n",
      "Epoch 561/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.7701 - val_loss: 646.2857\n",
      "Epoch 562/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.7035 - val_loss: 645.0996\n",
      "Epoch 563/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48.6187 - val_loss: 642.5948\n",
      "Epoch 564/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.5365 - val_loss: 640.8058\n",
      "Epoch 565/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.4544 - val_loss: 639.0591\n",
      "Epoch 566/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.3704 - val_loss: 636.7449\n",
      "Epoch 567/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48.2969 - val_loss: 634.9255\n",
      "Epoch 568/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48.2166 - val_loss: 632.1069\n",
      "Epoch 569/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.1520 - val_loss: 629.7943\n",
      "Epoch 570/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 48.0608 - val_loss: 628.7813\n",
      "Epoch 571/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.9710 - val_loss: 627.8920\n",
      "Epoch 572/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.9246 - val_loss: 628.6735\n",
      "Epoch 573/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47.8312 - val_loss: 626.6730\n",
      "Epoch 574/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47.7498 - val_loss: 624.6009\n",
      "Epoch 575/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.6677 - val_loss: 623.1476\n",
      "Epoch 576/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.5827 - val_loss: 622.2968\n",
      "Epoch 577/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.5192 - val_loss: 620.1187\n",
      "Epoch 578/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.4408 - val_loss: 619.8959\n",
      "Epoch 579/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.3763 - val_loss: 616.6341\n",
      "Epoch 580/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47.2593 - val_loss: 614.7716\n",
      "Epoch 581/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.1774 - val_loss: 613.1842\n",
      "Epoch 582/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.0962 - val_loss: 611.0031\n",
      "Epoch 583/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 47.0262 - val_loss: 608.9170\n",
      "Epoch 584/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.9412 - val_loss: 606.8300\n",
      "Epoch 585/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.8673 - val_loss: 605.8913\n",
      "Epoch 586/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.7800 - val_loss: 604.5828\n",
      "Epoch 587/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.7070 - val_loss: 602.2626\n",
      "Epoch 588/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.6176 - val_loss: 601.2179\n",
      "Epoch 589/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46.5332 - val_loss: 599.2443\n",
      "Epoch 590/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46.4548 - val_loss: 597.3485\n",
      "Epoch 591/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.3996 - val_loss: 594.7834\n",
      "Epoch 592/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.2971 - val_loss: 592.9481\n",
      "Epoch 593/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46.2064 - val_loss: 592.0652\n",
      "Epoch 594/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 46.1401 - val_loss: 591.1156\n",
      "Epoch 595/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46.0568 - val_loss: 590.0936\n",
      "Epoch 596/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.9756 - val_loss: 588.1434\n",
      "Epoch 597/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.8928 - val_loss: 586.4367\n",
      "Epoch 598/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.8292 - val_loss: 584.5439\n",
      "Epoch 599/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.7385 - val_loss: 583.5127\n",
      "Epoch 600/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.6599 - val_loss: 581.8652\n",
      "Epoch 601/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.5812 - val_loss: 580.8488\n",
      "Epoch 602/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.5062 - val_loss: 578.0137\n",
      "Epoch 603/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.4084 - val_loss: 576.2935\n",
      "Epoch 604/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.3318 - val_loss: 574.6340\n",
      "Epoch 605/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.2461 - val_loss: 572.8934\n",
      "Epoch 606/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45.1798 - val_loss: 570.5502\n",
      "Epoch 607/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.0881 - val_loss: 569.5946\n",
      "Epoch 608/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 45.0079 - val_loss: 568.1981\n",
      "Epoch 609/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.9441 - val_loss: 567.7756\n",
      "Epoch 610/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44.8447 - val_loss: 565.7776\n",
      "Epoch 611/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.7687 - val_loss: 563.6600\n",
      "Epoch 612/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.6979 - val_loss: 561.3256\n",
      "Epoch 613/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.6062 - val_loss: 560.5731\n",
      "Epoch 614/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.5265 - val_loss: 559.1683\n",
      "Epoch 615/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44.4381 - val_loss: 556.8854\n",
      "Epoch 616/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44.3948 - val_loss: 553.9794\n",
      "Epoch 617/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.2712 - val_loss: 552.8483\n",
      "Epoch 618/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.2233 - val_loss: 550.6512\n",
      "Epoch 619/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.1122 - val_loss: 549.2316\n",
      "Epoch 620/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.0370 - val_loss: 549.3285\n",
      "Epoch 621/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 43.9600 - val_loss: 547.6359\n",
      "Epoch 622/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 43.8822 - val_loss: 545.3628\n",
      "Epoch 623/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 43.8002 - val_loss: 543.7062\n",
      "Epoch 624/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43.7172 - val_loss: 542.2021\n",
      "Epoch 625/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 43.6433 - val_loss: 540.9901\n",
      "Epoch 626/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43.5671 - val_loss: 538.8353\n",
      "Epoch 627/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43.5330 - val_loss: 535.7365\n",
      "Epoch 628/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 43.4031 - val_loss: 535.1093\n",
      "Epoch 629/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 43.3222 - val_loss: 533.7796\n",
      "Epoch 630/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 43.2474 - val_loss: 531.6354\n",
      "Epoch 631/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43.1605 - val_loss: 530.8060\n",
      "Epoch 632/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 43.0915 - val_loss: 529.9601\n",
      "Epoch 633/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43.0097 - val_loss: 527.6232\n",
      "Epoch 634/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.9344 - val_loss: 525.9651\n",
      "Epoch 635/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.8527 - val_loss: 523.5527\n",
      "Epoch 636/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.7636 - val_loss: 522.3679\n",
      "Epoch 637/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.6930 - val_loss: 520.0167\n",
      "Epoch 638/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.6116 - val_loss: 518.3448\n",
      "Epoch 639/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.5318 - val_loss: 516.4838\n",
      "Epoch 640/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.4695 - val_loss: 516.4515\n",
      "Epoch 641/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.3716 - val_loss: 513.9609\n",
      "Epoch 642/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.3083 - val_loss: 511.1361\n",
      "Epoch 643/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.2061 - val_loss: 508.4300\n",
      "Epoch 644/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.1292 - val_loss: 506.9770\n",
      "Epoch 645/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.0435 - val_loss: 504.7282\n",
      "Epoch 646/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 41.9631 - val_loss: 503.2073\n",
      "Epoch 647/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 41.8870 - val_loss: 501.7591\n",
      "Epoch 648/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.8055 - val_loss: 499.7126\n",
      "Epoch 649/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.7408 - val_loss: 498.9332\n",
      "Epoch 650/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.6535 - val_loss: 497.0899\n",
      "Epoch 651/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.5609 - val_loss: 495.0868\n",
      "Epoch 652/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 41.4719 - val_loss: 492.2848\n",
      "Epoch 653/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.4097 - val_loss: 489.7418\n",
      "Epoch 654/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.3232 - val_loss: 489.1866\n",
      "Epoch 655/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.2525 - val_loss: 488.5391\n",
      "Epoch 656/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.1525 - val_loss: 485.9880\n",
      "Epoch 657/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 41.0656 - val_loss: 483.8389\n",
      "Epoch 658/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.9979 - val_loss: 481.7529\n",
      "Epoch 659/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 40.9153 - val_loss: 481.7446\n",
      "Epoch 660/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.8337 - val_loss: 480.4078\n",
      "Epoch 661/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.7608 - val_loss: 477.8710\n",
      "Epoch 662/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.6617 - val_loss: 476.7859\n",
      "Epoch 663/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.5911 - val_loss: 474.9557\n",
      "Epoch 664/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.5062 - val_loss: 473.9906\n",
      "Epoch 665/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 40.4321 - val_loss: 472.4931\n",
      "Epoch 666/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.3506 - val_loss: 470.8116\n",
      "Epoch 667/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 40.2830 - val_loss: 468.9368\n",
      "Epoch 668/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.2292 - val_loss: 466.2917\n",
      "Epoch 669/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.1281 - val_loss: 465.2729\n",
      "Epoch 670/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 40.0449 - val_loss: 465.4348\n",
      "Epoch 671/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.9952 - val_loss: 465.2094\n",
      "Epoch 672/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.9516 - val_loss: 463.9328\n",
      "Epoch 673/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.9052 - val_loss: 460.0377\n",
      "Epoch 674/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.8215 - val_loss: 459.8203\n",
      "Epoch 675/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.7497 - val_loss: 459.4821\n",
      "Epoch 676/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.6945 - val_loss: 458.4692\n",
      "Epoch 677/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 39.6252 - val_loss: 457.7471\n",
      "Epoch 678/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.5629 - val_loss: 457.3521\n",
      "Epoch 679/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.5326 - val_loss: 457.5721\n",
      "Epoch 680/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 39.4581 - val_loss: 456.4274\n",
      "Epoch 681/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.3885 - val_loss: 456.3717\n",
      "Epoch 682/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.3251 - val_loss: 455.7173\n",
      "Epoch 683/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.2682 - val_loss: 454.6819\n",
      "Epoch 684/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.1947 - val_loss: 454.2101\n",
      "Epoch 685/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 39.1405 - val_loss: 453.2966\n",
      "Epoch 686/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.0840 - val_loss: 452.8736\n",
      "Epoch 687/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 39.0276 - val_loss: 452.2362\n",
      "Epoch 688/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.9526 - val_loss: 451.5670\n",
      "Epoch 689/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.8882 - val_loss: 451.0143\n",
      "Epoch 690/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.8472 - val_loss: 450.7099\n",
      "Epoch 691/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.7659 - val_loss: 449.6660\n",
      "Epoch 692/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.7146 - val_loss: 449.1923\n",
      "Epoch 693/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 38.6557 - val_loss: 448.9459\n",
      "Epoch 694/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.5923 - val_loss: 447.7589\n",
      "Epoch 695/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.5211 - val_loss: 447.5367\n",
      "Epoch 696/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.4742 - val_loss: 446.3713\n",
      "Epoch 697/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.4070 - val_loss: 446.3923\n",
      "Epoch 698/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.3936 - val_loss: 444.9327\n",
      "Epoch 699/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 38.2755 - val_loss: 445.0129\n",
      "Epoch 700/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.2180 - val_loss: 444.8304\n",
      "Epoch 701/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.1526 - val_loss: 443.6483\n",
      "Epoch 702/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.1068 - val_loss: 442.7547\n",
      "Epoch 703/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 38.0180 - val_loss: 442.5416\n",
      "Epoch 704/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.9655 - val_loss: 441.8015\n",
      "Epoch 705/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 37.9043 - val_loss: 441.4450\n",
      "Epoch 706/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.8477 - val_loss: 441.0099\n",
      "Epoch 707/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.7797 - val_loss: 440.5392\n",
      "Epoch 708/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 37.7244 - val_loss: 438.9841\n",
      "Epoch 709/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.6665 - val_loss: 438.1939\n",
      "Epoch 710/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.5986 - val_loss: 437.9481\n",
      "Epoch 711/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 37.5248 - val_loss: 437.1777\n",
      "Epoch 712/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.4763 - val_loss: 436.3250\n",
      "Epoch 713/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 37.4123 - val_loss: 435.9203\n",
      "Epoch 714/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.3469 - val_loss: 435.3194\n",
      "Epoch 715/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 37.2966 - val_loss: 434.8222\n",
      "Epoch 716/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.2380 - val_loss: 434.6691\n",
      "Epoch 717/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.2023 - val_loss: 434.6078\n",
      "Epoch 718/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 37.0958 - val_loss: 433.3460\n",
      "Epoch 719/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 37.0347 - val_loss: 431.5692\n",
      "Epoch 720/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 36.9821 - val_loss: 430.7448\n",
      "Epoch 721/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 36.9210 - val_loss: 430.1399\n",
      "Epoch 722/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.8728 - val_loss: 429.4413\n",
      "Epoch 723/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 36.7956 - val_loss: 429.6100\n",
      "Epoch 724/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.7358 - val_loss: 429.4744\n",
      "Epoch 725/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.6821 - val_loss: 429.1442\n",
      "Epoch 726/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.6259 - val_loss: 427.8512\n",
      "Epoch 727/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.5608 - val_loss: 427.5327\n",
      "Epoch 728/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.5256 - val_loss: 427.4873\n",
      "Epoch 729/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.4502 - val_loss: 426.3564\n",
      "Epoch 730/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.3969 - val_loss: 426.1382\n",
      "Epoch 731/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 36.3396 - val_loss: 425.2748\n",
      "Epoch 732/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.2764 - val_loss: 424.6714\n",
      "Epoch 733/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.2201 - val_loss: 423.9708\n",
      "Epoch 734/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.1753 - val_loss: 423.2305\n",
      "Epoch 735/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.1173 - val_loss: 423.3874\n",
      "Epoch 736/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.0802 - val_loss: 423.2559\n",
      "Epoch 737/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.0297 - val_loss: 422.4479\n",
      "Epoch 738/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.9926 - val_loss: 421.9011\n",
      "Epoch 739/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.9524 - val_loss: 421.1269\n",
      "Epoch 740/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.9403 - val_loss: 419.8641\n",
      "Epoch 741/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.8553 - val_loss: 420.1022\n",
      "Epoch 742/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.8130 - val_loss: 419.5577\n",
      "Epoch 743/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.7790 - val_loss: 419.3001\n",
      "Epoch 744/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.7309 - val_loss: 418.2375\n",
      "Epoch 745/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.6919 - val_loss: 417.3155\n",
      "Epoch 746/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.6442 - val_loss: 417.0990\n",
      "Epoch 747/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.6110 - val_loss: 416.4518\n",
      "Epoch 748/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.5663 - val_loss: 415.7745\n",
      "Epoch 749/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.5147 - val_loss: 415.6063\n",
      "Epoch 750/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.4783 - val_loss: 415.3673\n",
      "Epoch 751/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.4468 - val_loss: 414.9850\n",
      "Epoch 752/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.4084 - val_loss: 414.0297\n",
      "Epoch 753/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.3674 - val_loss: 412.5340\n",
      "Epoch 754/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.3165 - val_loss: 412.1254\n",
      "Epoch 755/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.2795 - val_loss: 411.6844\n",
      "Epoch 756/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.2432 - val_loss: 411.6512\n",
      "Epoch 757/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.2096 - val_loss: 411.3246\n",
      "Epoch 758/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.1666 - val_loss: 410.7484\n",
      "Epoch 759/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.1198 - val_loss: 409.8496\n",
      "Epoch 760/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.0714 - val_loss: 408.9467\n",
      "Epoch 761/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 35.0481 - val_loss: 408.6351\n",
      "Epoch 762/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.9934 - val_loss: 407.8845\n",
      "Epoch 763/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.9631 - val_loss: 406.9985\n",
      "Epoch 764/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.9284 - val_loss: 406.1512\n",
      "Epoch 765/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.8952 - val_loss: 406.2956\n",
      "Epoch 766/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.8368 - val_loss: 405.9868\n",
      "Epoch 767/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.8101 - val_loss: 405.4846\n",
      "Epoch 768/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.7822 - val_loss: 404.2076\n",
      "Epoch 769/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.7357 - val_loss: 404.1841\n",
      "Epoch 770/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.6888 - val_loss: 403.6600\n",
      "Epoch 771/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.6685 - val_loss: 403.6310\n",
      "Epoch 772/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.6219 - val_loss: 402.6531\n",
      "Epoch 773/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.5715 - val_loss: 402.2551\n",
      "Epoch 774/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.5489 - val_loss: 401.1374\n",
      "Epoch 775/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.5010 - val_loss: 400.9233\n",
      "Epoch 776/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.4617 - val_loss: 400.1454\n",
      "Epoch 777/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.4277 - val_loss: 399.9636\n",
      "Epoch 778/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.3965 - val_loss: 399.3823\n",
      "Epoch 779/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.3669 - val_loss: 398.1803\n",
      "Epoch 780/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.3474 - val_loss: 398.4649\n",
      "Epoch 781/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.2704 - val_loss: 397.1537\n",
      "Epoch 782/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.2406 - val_loss: 396.6155\n",
      "Epoch 783/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.2102 - val_loss: 395.5485\n",
      "Epoch 784/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.1927 - val_loss: 395.7889\n",
      "Epoch 785/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.1442 - val_loss: 394.7490\n",
      "Epoch 786/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 34.0942 - val_loss: 394.3486\n",
      "Epoch 787/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.0645 - val_loss: 394.3580\n",
      "Epoch 788/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.0357 - val_loss: 393.1477\n",
      "Epoch 789/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.9969 - val_loss: 392.7487\n",
      "Epoch 790/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 33.9545 - val_loss: 391.9752\n",
      "Epoch 791/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.9269 - val_loss: 391.5965\n",
      "Epoch 792/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.9245 - val_loss: 390.4249\n",
      "Epoch 793/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.8553 - val_loss: 390.6723\n",
      "Epoch 794/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.8354 - val_loss: 389.9564\n",
      "Epoch 795/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.7934 - val_loss: 389.7004\n",
      "Epoch 796/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.7573 - val_loss: 389.0028\n",
      "Epoch 797/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.7467 - val_loss: 389.0502\n",
      "Epoch 798/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.6868 - val_loss: 387.9810\n",
      "Epoch 799/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.7099 - val_loss: 386.4665\n",
      "Epoch 800/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.6227 - val_loss: 386.8763\n",
      "Epoch 801/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.6040 - val_loss: 387.1068\n",
      "Epoch 802/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.5602 - val_loss: 386.6359\n",
      "Epoch 803/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.5368 - val_loss: 385.2642\n",
      "Epoch 804/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.4868 - val_loss: 384.6680\n",
      "Epoch 805/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.4625 - val_loss: 384.0222\n",
      "Epoch 806/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.4358 - val_loss: 383.2593\n",
      "Epoch 807/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.3849 - val_loss: 383.1890\n",
      "Epoch 808/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.3593 - val_loss: 382.6728\n",
      "Epoch 809/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.3244 - val_loss: 382.3214\n",
      "Epoch 810/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.2927 - val_loss: 381.9507\n",
      "Epoch 811/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.2551 - val_loss: 381.5524\n",
      "Epoch 812/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.2329 - val_loss: 380.5455\n",
      "Epoch 813/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.2359 - val_loss: 378.9868\n",
      "Epoch 814/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.1527 - val_loss: 379.0354\n",
      "Epoch 815/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.1174 - val_loss: 378.6998\n",
      "Epoch 816/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.1177 - val_loss: 377.4571\n",
      "Epoch 817/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.0716 - val_loss: 378.0571\n",
      "Epoch 818/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 33.0197 - val_loss: 377.7256\n",
      "Epoch 819/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.9850 - val_loss: 376.6478\n",
      "Epoch 820/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.9558 - val_loss: 375.7148\n",
      "Epoch 821/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.9212 - val_loss: 375.1169\n",
      "Epoch 822/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.8890 - val_loss: 374.7326\n",
      "Epoch 823/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.8622 - val_loss: 374.0960\n",
      "Epoch 824/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.8242 - val_loss: 373.5368\n",
      "Epoch 825/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.7863 - val_loss: 373.5870\n",
      "Epoch 826/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.7556 - val_loss: 372.8782\n",
      "Epoch 827/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.7192 - val_loss: 372.6291\n",
      "Epoch 828/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.6894 - val_loss: 372.1877\n",
      "Epoch 829/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.6598 - val_loss: 371.4002\n",
      "Epoch 830/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.6707 - val_loss: 369.7888\n",
      "Epoch 831/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.5891 - val_loss: 369.6856\n",
      "Epoch 832/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.5777 - val_loss: 369.8018\n",
      "Epoch 833/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.5532 - val_loss: 368.4499\n",
      "Epoch 834/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.4974 - val_loss: 368.4221\n",
      "Epoch 835/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.4997 - val_loss: 366.9139\n",
      "Epoch 836/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.4370 - val_loss: 366.8790\n",
      "Epoch 837/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.3922 - val_loss: 366.3857\n",
      "Epoch 838/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.3726 - val_loss: 365.9018\n",
      "Epoch 839/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.3312 - val_loss: 365.9045\n",
      "Epoch 840/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.3128 - val_loss: 364.9799\n",
      "Epoch 841/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.2590 - val_loss: 364.6384\n",
      "Epoch 842/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.2528 - val_loss: 364.5384\n",
      "Epoch 843/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.2193 - val_loss: 362.7766\n",
      "Epoch 844/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.1746 - val_loss: 362.4422\n",
      "Epoch 845/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.1373 - val_loss: 362.0530\n",
      "Epoch 846/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.1113 - val_loss: 361.1773\n",
      "Epoch 847/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.0867 - val_loss: 361.3882\n",
      "Epoch 848/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.0341 - val_loss: 360.5980\n",
      "Epoch 849/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 32.0181 - val_loss: 359.8906\n",
      "Epoch 850/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.9677 - val_loss: 358.8687\n",
      "Epoch 851/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.9421 - val_loss: 358.1166\n",
      "Epoch 852/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.8959 - val_loss: 357.8982\n",
      "Epoch 853/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.8784 - val_loss: 357.2185\n",
      "Epoch 854/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.8281 - val_loss: 356.9146\n",
      "Epoch 855/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.7929 - val_loss: 356.4016\n",
      "Epoch 856/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.7658 - val_loss: 355.7282\n",
      "Epoch 857/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.7260 - val_loss: 354.9947\n",
      "Epoch 858/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.6982 - val_loss: 353.6199\n",
      "Epoch 859/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.6725 - val_loss: 352.9025\n",
      "Epoch 860/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.6261 - val_loss: 352.8705\n",
      "Epoch 861/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.6076 - val_loss: 353.0181\n",
      "Epoch 862/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.5778 - val_loss: 352.8807\n",
      "Epoch 863/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.5243 - val_loss: 352.8022\n",
      "Epoch 864/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.5271 - val_loss: 352.6737\n",
      "Epoch 865/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.4980 - val_loss: 352.6886\n",
      "Epoch 866/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.4697 - val_loss: 352.7891\n",
      "Epoch 867/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.4642 - val_loss: 352.6459\n",
      "Epoch 868/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.4291 - val_loss: 352.5745\n",
      "Epoch 869/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 31.4094 - val_loss: 352.4625\n",
      "Epoch 870/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.3916 - val_loss: 352.4520\n",
      "Epoch 871/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.3742 - val_loss: 352.4135\n",
      "Epoch 872/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.3626 - val_loss: 352.3629\n",
      "Epoch 873/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.3517 - val_loss: 352.3227\n",
      "Epoch 874/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.3198 - val_loss: 352.3245\n",
      "Epoch 875/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.3222 - val_loss: 352.3183\n",
      "Epoch 876/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.2898 - val_loss: 352.1459\n",
      "Epoch 877/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.2641 - val_loss: 352.0751\n",
      "Epoch 878/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.2554 - val_loss: 351.9495\n",
      "Epoch 879/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.2265 - val_loss: 351.9543\n",
      "Epoch 880/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.2124 - val_loss: 351.8995\n",
      "Epoch 881/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.1950 - val_loss: 351.8357\n",
      "Epoch 882/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.1771 - val_loss: 351.8972\n",
      "Epoch 883/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.1660 - val_loss: 351.7936\n",
      "Epoch 884/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.1344 - val_loss: 351.7139\n",
      "Epoch 885/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.1105 - val_loss: 351.6421\n",
      "Epoch 886/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.0990 - val_loss: 351.6426\n",
      "Epoch 887/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.0760 - val_loss: 351.5005\n",
      "Epoch 888/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.0497 - val_loss: 351.4435\n",
      "Epoch 889/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.0391 - val_loss: 351.5210\n",
      "Epoch 890/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 31.0146 - val_loss: 351.4218\n",
      "Epoch 891/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.9931 - val_loss: 351.2836\n",
      "Epoch 892/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.9833 - val_loss: 351.1110\n",
      "Epoch 893/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.9712 - val_loss: 351.1864\n",
      "Epoch 894/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.9518 - val_loss: 351.1059\n",
      "Epoch 895/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.9144 - val_loss: 351.0538\n",
      "Epoch 896/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.9333 - val_loss: 350.9161\n",
      "Epoch 897/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.8883 - val_loss: 351.0090\n",
      "Epoch 898/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.8612 - val_loss: 350.9395\n",
      "Epoch 899/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.8380 - val_loss: 350.8987\n",
      "Epoch 900/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.8173 - val_loss: 350.8103\n",
      "Epoch 901/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.8124 - val_loss: 350.6467\n",
      "Epoch 902/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.7806 - val_loss: 350.6176\n",
      "Epoch 903/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.7741 - val_loss: 350.5831\n",
      "Epoch 904/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.7410 - val_loss: 350.5771\n",
      "Epoch 905/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.7246 - val_loss: 350.4887\n",
      "Epoch 906/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.6990 - val_loss: 350.4734\n",
      "Epoch 907/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.6940 - val_loss: 350.3798\n",
      "Epoch 908/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.6575 - val_loss: 350.4177\n",
      "Epoch 909/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.6567 - val_loss: 350.3271\n",
      "Epoch 910/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.6342 - val_loss: 350.3266\n",
      "Epoch 911/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.6468 - val_loss: 350.0398\n",
      "Epoch 912/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.5908 - val_loss: 350.0047\n",
      "Epoch 913/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.5727 - val_loss: 350.0458\n",
      "Epoch 914/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.5514 - val_loss: 350.0231\n",
      "Epoch 915/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.5281 - val_loss: 349.8903\n",
      "Epoch 916/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.5119 - val_loss: 349.8077\n",
      "Epoch 917/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.4908 - val_loss: 349.8184\n",
      "Epoch 918/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.4860 - val_loss: 349.8150\n",
      "Epoch 919/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.4618 - val_loss: 349.6525\n",
      "Epoch 920/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.4337 - val_loss: 349.6063\n",
      "Epoch 921/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.4088 - val_loss: 349.5524\n",
      "Epoch 922/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.3985 - val_loss: 349.5154\n",
      "Epoch 923/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.3985 - val_loss: 349.3257\n",
      "Epoch 924/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.3525 - val_loss: 349.3947\n",
      "Epoch 925/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.3268 - val_loss: 349.3404\n",
      "Epoch 926/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.3172 - val_loss: 349.3342\n",
      "Epoch 927/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.2955 - val_loss: 349.1647\n",
      "Epoch 928/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.2811 - val_loss: 349.0938\n",
      "Epoch 929/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.2615 - val_loss: 349.1772\n",
      "Epoch 930/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.2390 - val_loss: 349.0367\n",
      "Epoch 931/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.2101 - val_loss: 349.0351\n",
      "Epoch 932/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.2011 - val_loss: 348.9308\n",
      "Epoch 933/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.1719 - val_loss: 348.8231\n",
      "Epoch 934/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.1504 - val_loss: 348.7900\n",
      "Epoch 935/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.1330 - val_loss: 348.7829\n",
      "Epoch 936/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.1228 - val_loss: 348.6227\n",
      "Epoch 937/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.1160 - val_loss: 348.5072\n",
      "Epoch 938/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.1158 - val_loss: 348.6531\n",
      "Epoch 939/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.0740 - val_loss: 348.4946\n",
      "Epoch 940/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.0344 - val_loss: 348.4517\n",
      "Epoch 941/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 30.0318 - val_loss: 348.5072\n",
      "Epoch 942/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.0212 - val_loss: 348.3302\n",
      "Epoch 943/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.9821 - val_loss: 348.2898\n",
      "Epoch 944/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.9549 - val_loss: 348.2162\n",
      "Epoch 945/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.9410 - val_loss: 348.1395\n",
      "Epoch 946/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.9191 - val_loss: 348.0398\n",
      "Epoch 947/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.8966 - val_loss: 347.9737\n",
      "Epoch 948/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 29.8798 - val_loss: 347.8835\n",
      "Epoch 949/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.8637 - val_loss: 347.9155\n",
      "Epoch 950/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.8698 - val_loss: 347.7140\n",
      "Epoch 951/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.8196 - val_loss: 347.7789\n",
      "Epoch 952/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.7982 - val_loss: 347.6662\n",
      "Epoch 953/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.7727 - val_loss: 347.6688\n",
      "Epoch 954/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.7727 - val_loss: 347.6947\n",
      "Epoch 955/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.7560 - val_loss: 347.4669\n",
      "Epoch 956/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.7154 - val_loss: 347.4550\n",
      "Epoch 957/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.6903 - val_loss: 347.3711\n",
      "Epoch 958/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.6823 - val_loss: 347.3012\n",
      "Epoch 959/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.6825 - val_loss: 347.3340\n",
      "Epoch 960/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.6128 - val_loss: 347.0956\n",
      "Epoch 961/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.6324 - val_loss: 347.0158\n",
      "Epoch 962/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.5959 - val_loss: 346.9551\n",
      "Epoch 963/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.5690 - val_loss: 346.9929\n",
      "Epoch 964/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.5514 - val_loss: 346.9382\n",
      "Epoch 965/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.5396 - val_loss: 347.0025\n",
      "Epoch 966/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.5091 - val_loss: 346.9155\n",
      "Epoch 967/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.5021 - val_loss: 346.8808\n",
      "Epoch 968/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.4811 - val_loss: 346.7049\n",
      "Epoch 969/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4737 - val_loss: 346.6629\n",
      "Epoch 970/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.4652 - val_loss: 346.7483\n",
      "Epoch 971/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4749 - val_loss: 346.7783\n",
      "Epoch 972/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4367 - val_loss: 346.5749\n",
      "Epoch 973/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.4240 - val_loss: 346.5450\n",
      "Epoch 974/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.4136 - val_loss: 346.4694\n",
      "Epoch 975/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4233 - val_loss: 346.5692\n",
      "Epoch 976/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.3913 - val_loss: 346.4679\n",
      "Epoch 977/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3757 - val_loss: 346.3973\n",
      "Epoch 978/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3725 - val_loss: 346.3264\n",
      "Epoch 979/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3668 - val_loss: 346.3430\n",
      "Epoch 980/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3656 - val_loss: 346.1920\n",
      "Epoch 981/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3384 - val_loss: 346.1891\n",
      "Epoch 982/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3238 - val_loss: 346.2055\n",
      "Epoch 983/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3158 - val_loss: 346.2932\n",
      "Epoch 984/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.3505 - val_loss: 346.2847\n",
      "Epoch 985/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.2775 - val_loss: 346.0592\n",
      "Epoch 986/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.3110 - val_loss: 345.8206\n",
      "Epoch 987/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.2941 - val_loss: 345.9490\n",
      "Epoch 988/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.2558 - val_loss: 345.9339\n",
      "Epoch 989/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.2506 - val_loss: 345.9277\n",
      "Epoch 990/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.2352 - val_loss: 345.8614\n",
      "Epoch 991/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.2278 - val_loss: 345.8396\n",
      "Epoch 992/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.2140 - val_loss: 345.7916\n",
      "Epoch 993/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.2042 - val_loss: 345.7857\n",
      "Epoch 994/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.2137 - val_loss: 345.6649\n",
      "Epoch 995/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.1817 - val_loss: 345.6452\n",
      "Epoch 996/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.1702 - val_loss: 345.6088\n",
      "Epoch 997/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.1604 - val_loss: 345.6031\n",
      "Epoch 998/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.1733 - val_loss: 345.4353\n",
      "Epoch 999/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.1445 - val_loss: 345.4453\n",
      "Epoch 1000/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.1228 - val_loss: 345.4702\n",
      "Epoch 1001/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.1201 - val_loss: 345.4445\n",
      "Epoch 1002/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.1013 - val_loss: 345.2798\n",
      "Epoch 1003/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.0998 - val_loss: 345.1567\n",
      "Epoch 1004/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.0851 - val_loss: 345.2114\n",
      "Epoch 1005/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.0715 - val_loss: 345.2880\n",
      "Epoch 1006/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.0586 - val_loss: 345.2453\n",
      "Epoch 1007/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.0417 - val_loss: 345.1221\n",
      "Epoch 1008/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.0411 - val_loss: 344.9596\n",
      "Epoch 1009/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.0254 - val_loss: 344.9353\n",
      "Epoch 1010/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.0165 - val_loss: 344.9499\n",
      "Epoch 1011/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.0059 - val_loss: 344.8907\n",
      "Epoch 1012/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 29.0336 - val_loss: 344.9791\n",
      "Epoch 1013/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.9981 - val_loss: 344.7638\n",
      "Epoch 1014/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.9704 - val_loss: 344.7405\n",
      "Epoch 1015/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.9682 - val_loss: 344.6394\n",
      "Epoch 1016/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.9510 - val_loss: 344.6705\n",
      "Epoch 1017/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.9301 - val_loss: 344.7655\n",
      "Epoch 1018/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.9443 - val_loss: 344.7337\n",
      "Epoch 1019/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.9254 - val_loss: 344.5584\n",
      "Epoch 1020/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.9044 - val_loss: 344.4996\n",
      "Epoch 1021/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.9059 - val_loss: 344.3825\n",
      "Epoch 1022/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.9194 - val_loss: 344.5008\n",
      "Epoch 1023/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.8892 - val_loss: 344.4851\n",
      "Epoch 1024/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.8706 - val_loss: 344.3677\n",
      "Epoch 1025/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.8639 - val_loss: 344.2920\n",
      "Epoch 1026/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.8541 - val_loss: 344.3631\n",
      "Epoch 1027/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 28.8347 - val_loss: 344.2490\n",
      "Epoch 1028/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.8371 - val_loss: 344.1402\n",
      "Epoch 1029/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.8195 - val_loss: 344.1284\n",
      "Epoch 1030/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.8013 - val_loss: 344.2140\n",
      "Epoch 1031/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.8006 - val_loss: 344.1407\n",
      "Epoch 1032/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.7891 - val_loss: 344.0717\n",
      "Epoch 1033/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.7800 - val_loss: 343.9510\n",
      "Epoch 1034/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.7703 - val_loss: 343.9855\n",
      "Epoch 1035/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.7671 - val_loss: 343.8244\n",
      "Epoch 1036/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.7520 - val_loss: 343.8352\n",
      "Epoch 1037/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.7360 - val_loss: 343.8886\n",
      "Epoch 1038/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.7286 - val_loss: 343.8504\n",
      "Epoch 1039/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.7212 - val_loss: 343.7474\n",
      "Epoch 1040/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.7161 - val_loss: 343.6726\n",
      "Epoch 1041/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.7215 - val_loss: 343.6100\n",
      "Epoch 1042/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6960 - val_loss: 343.7050\n",
      "Epoch 1043/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6830 - val_loss: 343.6122\n",
      "Epoch 1044/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6828 - val_loss: 343.5245\n",
      "Epoch 1045/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6667 - val_loss: 343.5028\n",
      "Epoch 1046/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6536 - val_loss: 343.5533\n",
      "Epoch 1047/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6562 - val_loss: 343.4266\n",
      "Epoch 1048/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6411 - val_loss: 343.4281\n",
      "Epoch 1049/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6282 - val_loss: 343.3620\n",
      "Epoch 1050/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.6268 - val_loss: 343.3176\n",
      "Epoch 1051/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6215 - val_loss: 343.2039\n",
      "Epoch 1052/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6108 - val_loss: 343.2551\n",
      "Epoch 1053/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.6235 - val_loss: 343.1347\n",
      "Epoch 1054/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.5864 - val_loss: 343.2015\n",
      "Epoch 1055/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.5786 - val_loss: 343.2312\n",
      "Epoch 1056/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.5799 - val_loss: 343.0851\n",
      "Epoch 1057/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.5705 - val_loss: 343.0194\n",
      "Epoch 1058/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.5583 - val_loss: 342.9671\n",
      "Epoch 1059/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.5451 - val_loss: 343.0391\n",
      "Epoch 1060/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.5339 - val_loss: 342.9158\n",
      "Epoch 1061/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.5248 - val_loss: 342.8419\n",
      "Epoch 1062/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.5245 - val_loss: 342.8709\n",
      "Epoch 1063/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.5039 - val_loss: 342.7490\n",
      "Epoch 1064/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.4986 - val_loss: 342.7090\n",
      "Epoch 1065/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4973 - val_loss: 342.6850\n",
      "Epoch 1066/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4838 - val_loss: 342.6879\n",
      "Epoch 1067/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4725 - val_loss: 342.7074\n",
      "Epoch 1068/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.4784 - val_loss: 342.6283\n",
      "Epoch 1069/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4622 - val_loss: 342.6114\n",
      "Epoch 1070/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4592 - val_loss: 342.6122\n",
      "Epoch 1071/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4733 - val_loss: 342.4719\n",
      "Epoch 1072/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4368 - val_loss: 342.5718\n",
      "Epoch 1073/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4379 - val_loss: 342.4930\n",
      "Epoch 1074/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4333 - val_loss: 342.3363\n",
      "Epoch 1075/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4187 - val_loss: 342.3644\n",
      "Epoch 1076/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4115 - val_loss: 342.3321\n",
      "Epoch 1077/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.4047 - val_loss: 342.3300\n",
      "Epoch 1078/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3918 - val_loss: 342.2469\n",
      "Epoch 1079/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.4068 - val_loss: 342.2368\n",
      "Epoch 1080/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3636 - val_loss: 342.1096\n",
      "Epoch 1081/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3637 - val_loss: 342.0178\n",
      "Epoch 1082/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3838 - val_loss: 342.1300\n",
      "Epoch 1083/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3447 - val_loss: 342.0125\n",
      "Epoch 1084/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3395 - val_loss: 341.9716\n",
      "Epoch 1085/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3573 - val_loss: 342.0149\n",
      "Epoch 1086/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.3259 - val_loss: 341.8848\n",
      "Epoch 1087/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.3066 - val_loss: 341.8143\n",
      "Epoch 1088/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.3115 - val_loss: 341.7426\n",
      "Epoch 1089/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.3011 - val_loss: 341.8136\n",
      "Epoch 1090/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2844 - val_loss: 341.7712\n",
      "Epoch 1091/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2914 - val_loss: 341.7039\n",
      "Epoch 1092/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.2819 - val_loss: 341.6084\n",
      "Epoch 1093/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.2910 - val_loss: 341.7679\n",
      "Epoch 1094/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2621 - val_loss: 341.6355\n",
      "Epoch 1095/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2475 - val_loss: 341.5455\n",
      "Epoch 1096/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2386 - val_loss: 341.5279\n",
      "Epoch 1097/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.2367 - val_loss: 341.4289\n",
      "Epoch 1098/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2222 - val_loss: 341.4286\n",
      "Epoch 1099/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2131 - val_loss: 341.4756\n",
      "Epoch 1100/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2130 - val_loss: 341.4948\n",
      "Epoch 1101/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2190 - val_loss: 341.3416\n",
      "Epoch 1102/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1999 - val_loss: 341.2203\n",
      "Epoch 1103/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1882 - val_loss: 341.2722\n",
      "Epoch 1104/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1853 - val_loss: 341.1664\n",
      "Epoch 1105/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1854 - val_loss: 341.2561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1106/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1647 - val_loss: 341.1674\n",
      "Epoch 1107/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1613 - val_loss: 341.0239\n",
      "Epoch 1108/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1459 - val_loss: 341.0150\n",
      "Epoch 1109/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1396 - val_loss: 341.0707\n",
      "Epoch 1110/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1385 - val_loss: 341.0389\n",
      "Epoch 1111/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1247 - val_loss: 340.9372\n",
      "Epoch 1112/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1657 - val_loss: 341.0027\n",
      "Epoch 1113/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.2327 - val_loss: 340.7235\n",
      "Epoch 1114/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1263 - val_loss: 340.9417\n",
      "Epoch 1115/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1324 - val_loss: 341.0842\n",
      "Epoch 1116/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1381 - val_loss: 340.9241\n",
      "Epoch 1117/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1383 - val_loss: 340.8515\n",
      "Epoch 1118/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1289 - val_loss: 341.0354\n",
      "Epoch 1119/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1221 - val_loss: 340.9631\n",
      "Epoch 1120/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1104 - val_loss: 340.8925\n",
      "Epoch 1121/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1294 - val_loss: 340.7678\n",
      "Epoch 1122/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1277 - val_loss: 340.8819\n",
      "Epoch 1123/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1124 - val_loss: 340.8527\n",
      "Epoch 1124/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1291 - val_loss: 340.9471\n",
      "Epoch 1125/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1052 - val_loss: 340.8467\n",
      "Epoch 1126/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1189 - val_loss: 340.8463\n",
      "Epoch 1127/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1148 - val_loss: 340.8474\n",
      "Epoch 1128/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1058 - val_loss: 340.8918\n",
      "Epoch 1129/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1233 - val_loss: 340.9784\n",
      "Epoch 1130/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1235 - val_loss: 340.8293\n",
      "Epoch 1131/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1059 - val_loss: 340.8346\n",
      "Epoch 1132/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1156 - val_loss: 340.8891\n",
      "Epoch 1133/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1086 - val_loss: 340.9061\n",
      "Epoch 1134/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1122 - val_loss: 340.8750\n",
      "Epoch 1135/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1203 - val_loss: 340.9846\n",
      "Epoch 1136/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1226 - val_loss: 340.8483\n",
      "Epoch 1137/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1040 - val_loss: 340.8954\n",
      "Epoch 1138/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1066 - val_loss: 340.8726\n",
      "Epoch 1139/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1222 - val_loss: 340.8130\n",
      "Epoch 1140/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0952 - val_loss: 340.9127\n",
      "Epoch 1141/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1187 - val_loss: 341.0634\n",
      "Epoch 1142/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1152 - val_loss: 340.9420\n",
      "Epoch 1143/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1077 - val_loss: 340.8672\n",
      "Epoch 1144/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1077 - val_loss: 340.7779\n",
      "Epoch 1145/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1049 - val_loss: 340.8358\n",
      "Epoch 1146/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0896 - val_loss: 340.9512\n",
      "Epoch 1147/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1163 - val_loss: 340.9854\n",
      "Epoch 1148/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0999 - val_loss: 340.9240\n",
      "Epoch 1149/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1074 - val_loss: 340.7419\n",
      "Epoch 1150/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0975 - val_loss: 340.8011\n",
      "Epoch 1151/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0999 - val_loss: 340.8885\n",
      "Epoch 1152/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1080 - val_loss: 340.7536\n",
      "Epoch 1153/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0928 - val_loss: 340.7713\n",
      "Epoch 1154/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1069 - val_loss: 340.8968\n",
      "Epoch 1155/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0890 - val_loss: 340.8845\n",
      "Epoch 1156/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0919 - val_loss: 340.8281\n",
      "Epoch 1157/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0847 - val_loss: 340.8597\n",
      "Epoch 1158/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0957 - val_loss: 340.8077\n",
      "Epoch 1159/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0912 - val_loss: 340.9099\n",
      "Epoch 1160/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0846 - val_loss: 340.9135\n",
      "Epoch 1161/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0895 - val_loss: 340.8770\n",
      "Epoch 1162/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0881 - val_loss: 340.9652\n",
      "Epoch 1163/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1112 - val_loss: 340.8183\n",
      "Epoch 1164/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.1002 - val_loss: 340.9648\n",
      "Epoch 1165/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0902 - val_loss: 340.9684\n",
      "Epoch 1166/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0987 - val_loss: 340.7881\n",
      "Epoch 1167/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0851 - val_loss: 340.8118\n",
      "Epoch 1168/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0877 - val_loss: 340.9268\n",
      "Epoch 1169/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0929 - val_loss: 341.0075\n",
      "Epoch 1170/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0774 - val_loss: 340.9124\n",
      "Epoch 1171/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0858 - val_loss: 340.8093\n",
      "Epoch 1172/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0790 - val_loss: 340.8027\n",
      "Epoch 1173/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0904 - val_loss: 340.8220\n",
      "Epoch 1174/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0740 - val_loss: 340.9232\n",
      "Epoch 1175/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0903 - val_loss: 340.9420\n",
      "Epoch 1176/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0923 - val_loss: 340.8401\n",
      "Epoch 1177/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0844 - val_loss: 340.9619\n",
      "Epoch 1178/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0732 - val_loss: 340.9343\n",
      "Epoch 1179/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0771 - val_loss: 340.9496\n",
      "Epoch 1180/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0691 - val_loss: 340.9288\n",
      "Epoch 1181/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0726 - val_loss: 340.9684\n",
      "Epoch 1182/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0860 - val_loss: 340.8384\n",
      "Epoch 1183/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0710 - val_loss: 340.9228\n",
      "Epoch 1184/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0699 - val_loss: 340.9080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1185/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0698 - val_loss: 340.8982\n",
      "Epoch 1186/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0663 - val_loss: 340.9413\n",
      "Epoch 1187/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0642 - val_loss: 340.9385\n",
      "Epoch 1188/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0633 - val_loss: 340.9579\n",
      "Epoch 1189/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0626 - val_loss: 340.9031\n",
      "Epoch 1190/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0673 - val_loss: 340.8608\n",
      "Epoch 1191/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0637 - val_loss: 340.9245\n",
      "Epoch 1192/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0602 - val_loss: 340.9709\n",
      "Epoch 1193/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0742 - val_loss: 340.8786\n",
      "Epoch 1194/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0614 - val_loss: 340.9514\n",
      "Epoch 1195/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0635 - val_loss: 340.9697\n",
      "Epoch 1196/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0625 - val_loss: 340.9244\n",
      "Epoch 1197/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0942 - val_loss: 341.0921\n",
      "Epoch 1198/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0832 - val_loss: 340.9317\n",
      "Epoch 1199/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0617 - val_loss: 340.9118\n",
      "Epoch 1200/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0550 - val_loss: 340.9796\n",
      "Epoch 1201/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0548 - val_loss: 340.9312\n",
      "Epoch 1202/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0587 - val_loss: 340.9191\n",
      "Epoch 1203/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0551 - val_loss: 340.8227\n",
      "Epoch 1204/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0787 - val_loss: 340.7668\n",
      "Epoch 1205/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0736 - val_loss: 341.0031\n",
      "Epoch 1206/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0581 - val_loss: 340.9557\n",
      "Epoch 1207/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0499 - val_loss: 340.9170\n",
      "Epoch 1208/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0538 - val_loss: 340.8700\n",
      "Epoch 1209/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0512 - val_loss: 340.8371\n",
      "Epoch 1210/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0515 - val_loss: 340.9216\n",
      "Epoch 1211/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0461 - val_loss: 340.9825\n",
      "Epoch 1212/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0516 - val_loss: 340.9888\n",
      "Epoch 1213/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0424 - val_loss: 340.8601\n",
      "Epoch 1214/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0597 - val_loss: 340.8171\n",
      "Epoch 1215/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0460 - val_loss: 340.9415\n",
      "Epoch 1216/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0444 - val_loss: 340.9884\n",
      "Epoch 1217/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0516 - val_loss: 340.8583\n",
      "Epoch 1218/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0438 - val_loss: 340.8325\n",
      "Epoch 1219/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0464 - val_loss: 340.9413\n",
      "Epoch 1220/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0637 - val_loss: 340.9639\n",
      "Epoch 1221/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0326 - val_loss: 340.6933\n",
      "Epoch 1222/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0633 - val_loss: 340.6808\n",
      "Epoch 1223/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0545 - val_loss: 340.8936\n",
      "Epoch 1224/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0570 - val_loss: 340.9687\n",
      "Epoch 1225/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0365 - val_loss: 340.8836\n",
      "Epoch 1226/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0336 - val_loss: 340.8408\n",
      "Epoch 1227/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0406 - val_loss: 340.7617\n",
      "Epoch 1228/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0370 - val_loss: 340.7748\n",
      "Epoch 1229/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0369 - val_loss: 340.7856\n",
      "Epoch 1230/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0378 - val_loss: 340.8515\n",
      "Epoch 1231/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0333 - val_loss: 340.9007\n",
      "Epoch 1232/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0402 - val_loss: 340.8800\n",
      "Epoch 1233/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0299 - val_loss: 340.8492\n",
      "Epoch 1234/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0633 - val_loss: 340.7159\n",
      "Epoch 1235/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0401 - val_loss: 340.9380\n",
      "Epoch 1236/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0479 - val_loss: 340.8574\n",
      "Epoch 1237/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0532 - val_loss: 341.0057\n",
      "Epoch 1238/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0351 - val_loss: 340.9661\n",
      "Epoch 1239/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0182 - val_loss: 340.8432\n",
      "Epoch 1240/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0239 - val_loss: 340.7795\n",
      "Epoch 1241/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0390 - val_loss: 340.7591\n",
      "Epoch 1242/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0368 - val_loss: 340.9088\n",
      "Epoch 1243/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0643 - val_loss: 340.7860\n",
      "Epoch 1244/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0296 - val_loss: 340.9221\n",
      "Epoch 1245/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0229 - val_loss: 340.9156\n",
      "Epoch 1246/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0229 - val_loss: 340.9421\n",
      "Epoch 1247/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0193 - val_loss: 340.9148\n",
      "Epoch 1248/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0179 - val_loss: 340.8358\n",
      "Epoch 1249/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0245 - val_loss: 340.7377\n",
      "Epoch 1250/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0324 - val_loss: 340.8613\n",
      "Epoch 1251/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0268 - val_loss: 340.8915\n",
      "Epoch 1252/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0154 - val_loss: 340.8751\n",
      "Epoch 1253/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0254 - val_loss: 340.8006\n",
      "Epoch 1254/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0210 - val_loss: 340.8895\n",
      "Epoch 1255/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0129 - val_loss: 340.8694\n",
      "Epoch 1256/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0309 - val_loss: 340.9635\n",
      "Epoch 1257/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0385 - val_loss: 340.7352\n",
      "Epoch 1258/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0217 - val_loss: 340.7423\n",
      "Epoch 1259/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0200 - val_loss: 340.8672\n",
      "Epoch 1260/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0132 - val_loss: 340.8606\n",
      "Epoch 1261/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0086 - val_loss: 340.8278\n",
      "Epoch 1262/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0105 - val_loss: 340.8126\n",
      "Epoch 1263/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0138 - val_loss: 340.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1264/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0069 - val_loss: 340.7768\n",
      "Epoch 1265/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0217 - val_loss: 340.7753\n",
      "Epoch 1266/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0065 - val_loss: 340.8663\n",
      "Epoch 1267/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0199 - val_loss: 340.9262\n",
      "Epoch 1268/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9974 - val_loss: 340.7637\n",
      "Epoch 1269/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0348 - val_loss: 340.7044\n",
      "Epoch 1270/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0129 - val_loss: 340.8172\n",
      "Epoch 1271/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0160 - val_loss: 340.7609\n",
      "Epoch 1272/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0085 - val_loss: 340.7508\n",
      "Epoch 1273/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9986 - val_loss: 340.8731\n",
      "Epoch 1274/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0175 - val_loss: 340.9547\n",
      "Epoch 1275/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9995 - val_loss: 340.8070\n",
      "Epoch 1276/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9980 - val_loss: 340.7463\n",
      "Epoch 1277/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0021 - val_loss: 340.8113\n",
      "Epoch 1278/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9945 - val_loss: 340.8069\n",
      "Epoch 1279/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9950 - val_loss: 340.8017\n",
      "Epoch 1280/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0123 - val_loss: 340.8129\n",
      "Epoch 1281/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0010 - val_loss: 340.8409\n",
      "Epoch 1282/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9926 - val_loss: 340.8116\n",
      "Epoch 1283/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9920 - val_loss: 340.7873\n",
      "Epoch 1284/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9909 - val_loss: 340.7346\n",
      "Epoch 1285/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0145 - val_loss: 340.8663\n",
      "Epoch 1286/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9898 - val_loss: 340.7433\n",
      "Epoch 1287/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9902 - val_loss: 340.7471\n",
      "Epoch 1288/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9976 - val_loss: 340.7385\n",
      "Epoch 1289/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9868 - val_loss: 340.9148\n",
      "Epoch 1290/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9994 - val_loss: 340.9417\n",
      "Epoch 1291/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0017 - val_loss: 340.8360\n",
      "Epoch 1292/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9882 - val_loss: 340.7252\n",
      "Epoch 1293/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9915 - val_loss: 340.7621\n",
      "Epoch 1294/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9873 - val_loss: 340.7724\n",
      "Epoch 1295/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9830 - val_loss: 340.7443\n",
      "Epoch 1296/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9797 - val_loss: 340.7925\n",
      "Epoch 1297/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9803 - val_loss: 340.8058\n",
      "Epoch 1298/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9865 - val_loss: 340.8188\n",
      "Epoch 1299/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9870 - val_loss: 340.7687\n",
      "Epoch 1300/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9769 - val_loss: 340.8441\n",
      "Epoch 1301/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9938 - val_loss: 340.9113\n",
      "Epoch 1302/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9978 - val_loss: 340.8785\n",
      "Epoch 1303/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9559 - val_loss: 340.7346\n",
      "Epoch 1304/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0083 - val_loss: 340.5624\n",
      "Epoch 1305/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9957 - val_loss: 340.7299\n",
      "Epoch 1306/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9826 - val_loss: 340.8947\n",
      "Epoch 1307/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9774 - val_loss: 340.8532\n",
      "Epoch 1308/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9823 - val_loss: 340.7721\n",
      "Epoch 1309/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9772 - val_loss: 340.8098\n",
      "Epoch 1310/1500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27.9717 - val_loss: 340.8176\n",
      "Epoch 1311/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9772 - val_loss: 340.8734\n",
      "Epoch 1312/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9742 - val_loss: 340.8192\n",
      "Epoch 1313/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9820 - val_loss: 340.8992\n",
      "Epoch 1314/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9779 - val_loss: 340.7671\n",
      "Epoch 1315/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9705 - val_loss: 340.6650\n",
      "Epoch 1316/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9758 - val_loss: 340.7422\n",
      "Epoch 1317/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 28.0055 - val_loss: 340.8542\n",
      "Epoch 1318/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9930 - val_loss: 340.6817\n",
      "Epoch 1319/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9750 - val_loss: 340.7209\n",
      "Epoch 1320/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9692 - val_loss: 340.8619\n",
      "Epoch 1321/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9680 - val_loss: 340.8674\n",
      "Epoch 1322/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9604 - val_loss: 340.8219\n",
      "Epoch 1323/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9745 - val_loss: 340.7482\n",
      "Epoch 1324/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9624 - val_loss: 340.7932\n",
      "Epoch 1325/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9694 - val_loss: 340.8952\n",
      "Epoch 1326/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9627 - val_loss: 340.8512\n",
      "Epoch 1327/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9595 - val_loss: 340.7952\n",
      "Epoch 1328/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9649 - val_loss: 340.7181\n",
      "Epoch 1329/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9669 - val_loss: 340.7726\n",
      "Epoch 1330/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9816 - val_loss: 340.8417\n",
      "Epoch 1331/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9653 - val_loss: 340.6990\n",
      "Epoch 1332/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9614 - val_loss: 340.7053\n",
      "Epoch 1333/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9672 - val_loss: 340.8211\n",
      "Epoch 1334/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9551 - val_loss: 340.7822\n",
      "Epoch 1335/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9567 - val_loss: 340.7491\n",
      "Epoch 1336/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9553 - val_loss: 340.7146\n",
      "Epoch 1337/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9655 - val_loss: 340.8372\n",
      "Epoch 1338/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9529 - val_loss: 340.7599\n",
      "Epoch 1339/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9477 - val_loss: 340.7554\n",
      "Epoch 1340/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9663 - val_loss: 340.7387\n",
      "Epoch 1341/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9494 - val_loss: 340.7158\n",
      "Epoch 1342/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9551 - val_loss: 340.7729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1343/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9489 - val_loss: 340.7845\n",
      "Epoch 1344/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9484 - val_loss: 340.7701\n",
      "Epoch 1345/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9632 - val_loss: 340.7759\n",
      "Epoch 1346/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9479 - val_loss: 340.6861\n",
      "Epoch 1347/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9633 - val_loss: 340.7611\n",
      "Epoch 1348/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9430 - val_loss: 340.6722\n",
      "Epoch 1349/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9521 - val_loss: 340.7281\n",
      "Epoch 1350/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9455 - val_loss: 340.6712\n",
      "Epoch 1351/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9509 - val_loss: 340.7791\n",
      "Epoch 1352/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9429 - val_loss: 340.7603\n",
      "Epoch 1353/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9657 - val_loss: 340.8059\n",
      "Epoch 1354/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9471 - val_loss: 340.6729\n",
      "Epoch 1355/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9456 - val_loss: 340.7154\n",
      "Epoch 1356/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9370 - val_loss: 340.7299\n",
      "Epoch 1357/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9478 - val_loss: 340.8082\n",
      "Epoch 1358/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9467 - val_loss: 340.7896\n",
      "Epoch 1359/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9668 - val_loss: 340.6103\n",
      "Epoch 1360/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9384 - val_loss: 340.7290\n",
      "Epoch 1361/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9398 - val_loss: 340.8596\n",
      "Epoch 1362/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9361 - val_loss: 340.8071\n",
      "Epoch 1363/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9528 - val_loss: 340.6593\n",
      "Epoch 1364/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9337 - val_loss: 340.7484\n",
      "Epoch 1365/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9341 - val_loss: 340.7902\n",
      "Epoch 1366/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9783 - val_loss: 340.6079\n",
      "Epoch 1367/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9257 - val_loss: 340.8206\n",
      "Epoch 1368/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9412 - val_loss: 340.9079\n",
      "Epoch 1369/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9366 - val_loss: 340.8426\n",
      "Epoch 1370/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9280 - val_loss: 340.7282\n",
      "Epoch 1371/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9300 - val_loss: 340.6587\n",
      "Epoch 1372/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9365 - val_loss: 340.7895\n",
      "Epoch 1373/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9267 - val_loss: 340.7626\n",
      "Epoch 1374/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9356 - val_loss: 340.8513\n",
      "Epoch 1375/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9287 - val_loss: 340.7250\n",
      "Epoch 1376/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9284 - val_loss: 340.6850\n",
      "Epoch 1377/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9245 - val_loss: 340.7559\n",
      "Epoch 1378/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9274 - val_loss: 340.8054\n",
      "Epoch 1379/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9174 - val_loss: 340.7482\n",
      "Epoch 1380/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9421 - val_loss: 340.6154\n",
      "Epoch 1381/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9401 - val_loss: 340.8118\n",
      "Epoch 1382/1500\n",
      "8/8 [==============================] - ETA: 0s - loss: 27.49 - 0s 3ms/step - loss: 27.9233 - val_loss: 340.7781\n",
      "Epoch 1383/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9147 - val_loss: 340.7034\n",
      "Epoch 1384/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9276 - val_loss: 340.7132\n",
      "Epoch 1385/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9746 - val_loss: 340.5576\n",
      "Epoch 1386/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9230 - val_loss: 340.7963\n",
      "Epoch 1387/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9180 - val_loss: 340.8034\n",
      "Epoch 1388/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9195 - val_loss: 340.8029\n",
      "Epoch 1389/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9102 - val_loss: 340.7377\n",
      "Epoch 1390/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9064 - val_loss: 340.6760\n",
      "Epoch 1391/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9231 - val_loss: 340.7073\n",
      "Epoch 1392/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9250 - val_loss: 340.6416\n",
      "Epoch 1393/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9360 - val_loss: 340.7955\n",
      "Epoch 1394/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9069 - val_loss: 340.7261\n",
      "Epoch 1395/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9226 - val_loss: 340.6547\n",
      "Epoch 1396/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9357 - val_loss: 340.8482\n",
      "Epoch 1397/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9089 - val_loss: 340.7891\n",
      "Epoch 1398/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9177 - val_loss: 340.6392\n",
      "Epoch 1399/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9154 - val_loss: 340.6960\n",
      "Epoch 1400/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9038 - val_loss: 340.7668\n",
      "Epoch 1401/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9176 - val_loss: 340.8504\n",
      "Epoch 1402/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9042 - val_loss: 340.7844\n",
      "Epoch 1403/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8969 - val_loss: 340.6850\n",
      "Epoch 1404/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9190 - val_loss: 340.6577\n",
      "Epoch 1405/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9051 - val_loss: 340.7352\n",
      "Epoch 1406/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9005 - val_loss: 340.8231\n",
      "Epoch 1407/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9281 - val_loss: 340.8600\n",
      "Epoch 1408/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9450 - val_loss: 340.6695\n",
      "Epoch 1409/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9223 - val_loss: 340.8139\n",
      "Epoch 1410/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8954 - val_loss: 340.7829\n",
      "Epoch 1411/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8978 - val_loss: 340.7424\n",
      "Epoch 1412/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.0145 - val_loss: 340.5479\n",
      "Epoch 1413/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9054 - val_loss: 340.8428\n",
      "Epoch 1414/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9178 - val_loss: 340.9376\n",
      "Epoch 1415/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9197 - val_loss: 340.8750\n",
      "Epoch 1416/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9230 - val_loss: 340.6075\n",
      "Epoch 1417/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9278 - val_loss: 340.6034\n",
      "Epoch 1418/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8974 - val_loss: 340.8285\n",
      "Epoch 1419/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9009 - val_loss: 340.9117\n",
      "Epoch 1420/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9064 - val_loss: 340.8808\n",
      "Epoch 1421/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9089 - val_loss: 340.7411\n",
      "Epoch 1422/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8906 - val_loss: 340.8147\n",
      "Epoch 1423/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8919 - val_loss: 340.8459\n",
      "Epoch 1424/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8980 - val_loss: 340.8031\n",
      "Epoch 1425/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8860 - val_loss: 340.7612\n",
      "Epoch 1426/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8955 - val_loss: 340.8504\n",
      "Epoch 1427/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9078 - val_loss: 340.7534\n",
      "Epoch 1428/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8908 - val_loss: 340.8579\n",
      "Epoch 1429/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8909 - val_loss: 340.7622\n",
      "Epoch 1430/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8826 - val_loss: 340.7965\n",
      "Epoch 1431/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8822 - val_loss: 340.8794\n",
      "Epoch 1432/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8876 - val_loss: 340.8504\n",
      "Epoch 1433/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8774 - val_loss: 340.8408\n",
      "Epoch 1434/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8888 - val_loss: 340.7926\n",
      "Epoch 1435/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8953 - val_loss: 340.8775\n",
      "Epoch 1436/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9003 - val_loss: 340.8612\n",
      "Epoch 1437/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8861 - val_loss: 340.8807\n",
      "Epoch 1438/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8877 - val_loss: 340.7599\n",
      "Epoch 1439/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8853 - val_loss: 340.8571\n",
      "Epoch 1440/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8772 - val_loss: 340.8420\n",
      "Epoch 1441/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8678 - val_loss: 340.7364\n",
      "Epoch 1442/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8746 - val_loss: 340.7440\n",
      "Epoch 1443/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8768 - val_loss: 340.7817\n",
      "Epoch 1444/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8747 - val_loss: 340.7078\n",
      "Epoch 1445/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8999 - val_loss: 340.6469\n",
      "Epoch 1446/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8824 - val_loss: 340.8376\n",
      "Epoch 1447/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8965 - val_loss: 340.8458\n",
      "Epoch 1448/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8868 - val_loss: 340.8553\n",
      "Epoch 1449/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8785 - val_loss: 340.7104\n",
      "Epoch 1450/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.9154 - val_loss: 340.6728\n",
      "Epoch 1451/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8668 - val_loss: 340.8414\n",
      "Epoch 1452/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8761 - val_loss: 340.8736\n",
      "Epoch 1453/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8719 - val_loss: 340.8209\n",
      "Epoch 1454/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8732 - val_loss: 340.7471\n",
      "Epoch 1455/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8594 - val_loss: 340.8226\n",
      "Epoch 1456/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8634 - val_loss: 340.8505\n",
      "Epoch 1457/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8698 - val_loss: 340.7792\n",
      "Epoch 1458/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8639 - val_loss: 340.8498\n",
      "Epoch 1459/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8636 - val_loss: 340.7814\n",
      "Epoch 1460/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8609 - val_loss: 340.8031\n",
      "Epoch 1461/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8582 - val_loss: 340.8190\n",
      "Epoch 1462/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8725 - val_loss: 340.7572\n",
      "Epoch 1463/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8535 - val_loss: 340.8700\n",
      "Epoch 1464/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8621 - val_loss: 340.8933\n",
      "Epoch 1465/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8553 - val_loss: 340.7873\n",
      "Epoch 1466/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8645 - val_loss: 340.6932\n",
      "Epoch 1467/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8722 - val_loss: 340.7786\n",
      "Epoch 1468/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8535 - val_loss: 340.7080\n",
      "Epoch 1469/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8682 - val_loss: 340.7549\n",
      "Epoch 1470/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8515 - val_loss: 340.7836\n",
      "Epoch 1471/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8543 - val_loss: 340.8361\n",
      "Epoch 1472/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8564 - val_loss: 340.8097\n",
      "Epoch 1473/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8451 - val_loss: 340.7459\n",
      "Epoch 1474/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8975 - val_loss: 340.6241\n",
      "Epoch 1475/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.9056 - val_loss: 340.9055\n",
      "Epoch 1476/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8747 - val_loss: 340.7766\n",
      "Epoch 1477/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8486 - val_loss: 340.8198\n",
      "Epoch 1478/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8553 - val_loss: 340.7558\n",
      "Epoch 1479/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8514 - val_loss: 340.8526\n",
      "Epoch 1480/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8477 - val_loss: 340.8096\n",
      "Epoch 1481/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8605 - val_loss: 340.6828\n",
      "Epoch 1482/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8548 - val_loss: 340.6982\n",
      "Epoch 1483/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8514 - val_loss: 340.8620\n",
      "Epoch 1484/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8468 - val_loss: 340.8125\n",
      "Epoch 1485/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8465 - val_loss: 340.7809\n",
      "Epoch 1486/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8436 - val_loss: 340.7618\n",
      "Epoch 1487/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8457 - val_loss: 340.7750\n",
      "Epoch 1488/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8481 - val_loss: 340.7941\n",
      "Epoch 1489/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8507 - val_loss: 340.7715\n",
      "Epoch 1490/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8431 - val_loss: 340.7946\n",
      "Epoch 1491/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8462 - val_loss: 340.7324\n",
      "Epoch 1492/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8469 - val_loss: 340.7690\n",
      "Epoch 1493/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8402 - val_loss: 340.7714\n",
      "Epoch 1494/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8408 - val_loss: 340.7679\n",
      "Epoch 1495/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8385 - val_loss: 340.8047\n",
      "Epoch 1496/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8738 - val_loss: 340.6967\n",
      "Epoch 1497/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8301 - val_loss: 340.8268\n",
      "Epoch 1498/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8467 - val_loss: 340.8767\n",
      "Epoch 1499/1500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8324 - val_loss: 340.7911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/1500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 27.8262 - val_loss: 340.7140\n"
     ]
    }
   ],
   "source": [
    "# Initiating the optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss=losses.MeanAbsoluteError(), optimizer=optimizer)\n",
    "\n",
    "# Fitting the model\n",
    "history = model.fit(X, Y, epochs = 1500, batch_size=32, validation_data=(Xval, Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(mse))\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.plot(epochs, mse, 'r', label='Training loss', color='blue')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss', color='red')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1406.2684]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing input for the model \n",
    "x = xtest[X.columns].values.astype('float32')\n",
    "x = np.reshape(x, (1, X.shape[1]))\n",
    "\n",
    "# Predicting \n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting model weights\n",
    "w = [x[0] for x in model.weights[0].numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcoef = pd.DataFrame({'feature': X.columns, 'w': w})\n",
    "dcoef.sort_values('w', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>weekday_6</td>\n",
       "      <td>-0.574763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>is_cured-90-99Vyras</td>\n",
       "      <td>-0.510918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>is_cured-90-99Moteris</td>\n",
       "      <td>-0.426986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>is_quarantine</td>\n",
       "      <td>-0.411650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>weekday_5</td>\n",
       "      <td>-0.356620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>is_treated-20-29Vyras</td>\n",
       "      <td>0.747716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_cured-10-19Vyras</td>\n",
       "      <td>0.754963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>is_treated-60-69Vyras</td>\n",
       "      <td>0.761352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>is_treated-60-69Moteris</td>\n",
       "      <td>0.787507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>is_treated-40-49Moteris</td>\n",
       "      <td>0.812973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature         w\n",
       "98                 weekday_6 -0.574763\n",
       "23       is_cured-90-99Vyras -0.510918\n",
       "22     is_cured-90-99Moteris -0.426986\n",
       "101            is_quarantine -0.411650\n",
       "97                 weekday_5 -0.356620\n",
       "..                       ...       ...\n",
       "78     is_treated-20-29Vyras  0.747716\n",
       "4        is_cured-10-19Vyras  0.754963\n",
       "86     is_treated-60-69Vyras  0.761352\n",
       "85   is_treated-60-69Moteris  0.787507\n",
       "81   is_treated-40-49Moteris  0.812973\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
